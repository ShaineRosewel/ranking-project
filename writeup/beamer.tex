% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\usetheme[]{Madrid}
\usecolortheme{beaver}
\usefonttheme{structurebold}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\title[Joint Confidence Regions for Rankings]{Joint Confidence Regions for Rankings based on Correlated Estimates}
\author[Matala]{Matala, Shaine Rosewel}
\institute[UP Stat]{University of the Philippines}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{pgfpages}
\setbeameroption{show notes on second screen=right}
\usepackage{comment}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdfauthor={Matala, Shaine Rosewel},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{Matala, Shaine Rosewel}
\date{December 15, 2025}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}{Background of the Study}
\phantomsection\label{background-of-the-study}
\begin{itemize}[<+->]
\tightlist
\item
  In the problem of estimating ranks of several unknown real-valued
  parameters \(\theta_1,\theta_2,\ldots, \theta_K\), it is desired to
  rank these \(K\) parameters from smallest to largest,
  \(\theta_{(1)}<\theta_{(2)}<\ldots<\theta_{(K)}\).
\item
  Because rankings based on
  \(\hat\theta_1,\hat\theta_2,\ldots, \hat\theta_K\) can change due to
  sampling variability, statements of uncertainty should accompany
  released rankings.
\item
  The margin of error gives uncertainty in \(\hat\theta_k\) for each
  \(k\) separately.
\item
  A direct assessment of the uncertainty in the estimated overall
  ranking would simultaneously involve all units.
\end{itemize}

\note{
\begin{itemize}
  \item Example 30 day mortality rate in hospitals, mean travel time to work by Klein
  \item Such tables motivate "implicit" rankings.
  \item Because rankings based on the observed values of $\hat\theta_1,\hat\theta_2,\ldots, \hat\theta_K$ can vary because of sampling variability, widely understood statements of uncertainty should accompany each released ranking.
  \item While the margin of error gives uncertainty in the estimate $\hat\theta_k$ for each unit $k$ separately, A direct assessment of the uncertainty in the estimated overall ranking would jointly involve all units and their relative standing to each other.
  \item If we repeat the entire process of generating all \(K\) intervals many times, at least 95 percent of the time, all \(K\) of the resulting intervals will simultaneously contain their respective true parameters \(\theta _{1},\dots ,\theta _{K}\)
\end{itemize}
}
\end{frame}

\begin{frame}{Background of the Study}
\phantomsection\label{background-of-the-study-1}
\begin{itemize}[<+->]
\tightlist
\item
  Let \(r_1,r_2,\ldots,r_K\) be the true unknown ranks of
  \(\theta_1,\theta_2,\ldots, \theta_K\). A mathematical definition of
  \(r_k\) is as follows: \begin{equation}
  r_k = \sum^K_{j=1} I(\theta_j \leq \theta_k) = 1 + \sum_{j:j \neq k} I(\theta_j \leq \theta_k), \qquad \text{for} \; k = 1, 2, \dots, K.
  \notag
  \end{equation}
\item
  Example
\end{itemize}

\begin{center}
\uncover<2->{
\begin{tabular}{ |c|c|c| }
\hline
$k$ & $\hat\theta_k$ & $\hat r_k$ \\
\hline \hline
1 & \uncover<3->{12.3} & \uncover<4->{1} \\
2 & \uncover<3->{17.2} & \uncover<5->{2} \\  
3 & \uncover<3->{19.1} & \uncover<7->{5} \\  
4 & \uncover<3->{18.0} & \uncover<6->{3} \\  
5 & \uncover<3->{19.0} & \uncover<7->{4} \\  
\hline
\end{tabular}
}
\end{center}
\end{frame}

\begin{frame}{Klein's Approach}
\phantomsection\label{kleins-approach}
Klein et al.~(2020) assumes that
\(\hat{\theta}_k\sim N(\theta_k,\sigma^2_k), k=1,2,\ldots,K\) where
\(\theta_k\) is unknown but \(\sigma^2_k\) is known.

\uncover<2->{Suppose that for each \(k \in \left\{1, 2, \dots, K\right\}\) there exists values \(L_k\) and \(U_k\) ST

\begin{equation}
  \theta_k \in \left( L_k, U_k \right), k=1,2,\ldots,K,
  \label{eq:theta_int}
\end{equation}
}

\uncover<3->{
the range for \(r_k\) for each \(k \in \left\{1, 2, \dots, K\right\}\) is as follows:

\begin{equation}
  r_k \in 
  \left\{ 
  \lvert \Lambda_{Lk} \rvert + 1,  
  \lvert \Lambda_{Lk} \rvert + 2,
  \lvert \Lambda_{Lk} \rvert + 3,
  \dots,
  \lvert \Lambda_{Lk} \rvert + \lvert \Lambda_{Ok} \rvert + 1
  \right\}
  \label{eq:klein_jcs}
\end{equation}

\begin{align}
  \text{where } &I_k = \left\{1,2,\dots,K\right\}\setminus\left\{k\right\} \notag \\
  &\Lambda_{Lk} = \left\{ j\in I_k \mid U_j \le L_k \right\} \notag \\
  &\Lambda_{Ok} = \left\{ j\in I_k \mid U_j > L_k \text{ and } U_k > L_j \right\} \notag
\end{align}
}
\end{frame}

\begin{frame}{Klein's Approach}
\phantomsection\label{kleins-approach-1}
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| }
\hline
$k$ & $\hat\theta_k$ & $\hat r_k$ & $(L_k, U_k)$ & $\vert \Lambda_{Lk} \vert$ & $\vert \Lambda_{Ok} \vert$ & range \\
\hline \hline
1 & {12.3} & {1} & \uncover<2->{(11.0, 14.3)} & \uncover<4->{0} & \uncover<7->{1} & \uncover<10->{1,2} \\
2 & {17.2} & {2} & \uncover<3->{(14.1, 21.2)} & \uncover<5->{0} & \uncover<8->{4} & \uncover<11->{1,2,3,4,5} \\  
3 & {19.1} & {5} & \uncover<3->{(18.2, 20.1)} & \uncover<6->{2} & \uncover<9->{2} & \uncover<12->{3,4,5} \\  
4 & {18.0} & {3} & \uncover<3->{(17.3, 18.0)} & \uncover<6->{1} & \uncover<9->{1} & \uncover<12->{2,3} \\  
5 & {19.0} & {4} & \uncover<3->{(18.4, 21.0)} & \uncover<6->{2} & \uncover<9->{2} & \uncover<12->{3,4,5} \\  
\hline
\end{tabular}
\end{center}

\note{
\begin{itemize}
  \item Note that the number of elements in the range given in (\ref{eq:klein_jcs}) is $|\Lambda_{Ok}|+1$. 
\end{itemize}
}
\end{frame}

\begin{frame}{Klein's Approach}
\phantomsection\label{kleins-approach-2}
Suppose that for random quantities \(L_k\) and \(U_k\), the intervals
satisfy the following probability condition:

\begin{equation}
  P\left[ \bigcap^K_{k=1} \left\{ \theta_k \in \left(L_k, U_k\right) \right\} \right] \geq 1-\alpha;
  \label{eq:joint_cov1}
\end{equation}

\uncover<2->{
then, by the result of Klein et al. (2020), it also follows that

\begin{equation}
  P\left[
  \bigcap^K_{k=1}
  \left\{
  r_k \in 
  \left\{ 
  \lvert \Lambda_{Lk} \rvert + 1,  
  \lvert \Lambda_{Lk} \rvert + 2,
  \dots,
  \lvert \Lambda_{Lk} \rvert + \lvert \Lambda_{Ok} \rvert + 1
  \right\}
  \right\}
  \right] \geq 1-\alpha.
  \label{eq:joint_cov2}
\end{equation}
}

\note{
\begin{itemize}
  \item We want narrower confidence intervals for $\theta_1,\theta_2,\ldots,\theta_K$ since smaller difference between \(U_k\) and \(L_k\) leads to a smaller \(\lvert \Lambda_{Ok} \rvert\).
\end{itemize}
}
\end{frame}

\begin{frame}{Klein's Approach}
\phantomsection\label{kleins-approach-3}
\begin{itemize}[<+->]
\tightlist
\item
  Due to the assumption of normality on \(\hat{\theta}_k\) as well as
  the fact that \(\sigma_k\) is assumed known, Klein set the confidence
  intervals \((L_k,U_k)\) for \(\theta_k\) to be of the form
  \(\hat \theta_k \pm t \times \sigma_k\) for
  \(k \in \left\{1, 2, \dots, K\right\}\).
\end{itemize}

\begin{itemize}[<+->]
\tightlist
\item
  Bonferroni approach: \(t = z_{\alpha/2K}\)
\end{itemize}

\begin{itemize}[<+->]
\tightlist
\item
  Independence assumption: \(t = z_{\gamma/2}\) where
  \(\gamma=1-(1-\alpha)^{1/K}\)
\end{itemize}

\note{
\begin{itemize}
  \item One may use the Bonferroni approach to choose $t$. If such an approach is used, the choice of $t$ that would satisfy (\ref{eq:joint_cov1}) is $t = z_{\alpha/2K}$.
  \item Another choice of $t$ is one that exploits the independence assumption on $\hat{\theta}_k$. Such a choice is given by $z_{\gamma/2}$ where $\gamma=1-(1-\alpha)^{1/K}$
\end{itemize}
}
\end{frame}

\begin{frame}{Motivation}
\phantomsection\label{motivation}
\begin{itemize}[<+->]
\tightlist
\item
  Problem: Assuming independence when constructing joint confidence
  regions for estimators that are, in fact, correlated may lead to
  overly conservative and thus wider intervals, implying greater
  uncertainty.
\item
  Aim: develop a procedure capable of handling such dependencies while
  maintaining coverage close to the nominal level and producing
  relatively narrow joint confidence intervals.
\end{itemize}
\end{frame}

\begin{frame}{Motivation}
\phantomsection\label{motivation-1}
\begin{block}{Political setting --- David \& Legara (2015)}
\phantomsection\label{political-setting-david-legara-2015}
\begin{itemize}[<+->]
\tightlist
\item
  In weak-party systems, candidates who belong to the same political
  alliance or ticket commonly co-occur in ballots and hence perform with
  similarity.
\item
  Name recall is a powerful predictor of likely victory in elections.
\end{itemize}

\note{
\begin{itemize}
  \item Candidates with a name-recall advantage, such as media celebrities, incumbents, and members of dynastic families
  \item In the Philippine setting, candidates running under the same alliance often share campaign machinery and voter bases, which induces correlation in their vote totals across districts. Dependence may also arise from factors such as name recall, which can affect multiple candidates simultaneously, even across different alliances.
\end{itemize}
}
\end{block}
\end{frame}

\begin{frame}{Motivation}
\phantomsection\label{motivation-2}
\begin{block}{Measurement across geographies --- Klein et al.~(2020)}
\phantomsection\label{measurement-across-geographies-klein-et-al.-2020}
\begin{table}[h]
\centering
\begin{tabular}{p{1cm} p{4.5cm} p{4.5cm}}
\textbf{Travel Time} & \textbf{Population Density} & \textbf{Common Locations} \\ \hline
\uncover<2->{Shorter mean} &
\uncover<3->{Large unpopulated land areas; fewer high-density population centers} &
\uncover<5->{Mountain region and Central region states} \\[3pt] %3pt is the gap%
\uncover<2->{Longer mean} &
\uncover<4->{Highly urbanized areas with large populations and dense population centers} &
\uncover<6->{East Coast states} \\
\end{tabular}
\end{table}

\note{
\begin{itemize}
  \item Klein et al. (2020) also noted that states with large unpopulated land areas and relatively few high-density population centers tend to report shorter travel times while longer travel times are typically observed in highly urbanized states with large populations and high population densities.
  \item 2019---Many states with shorter travel times are located in the Mountain and Central regions, whereas majority of those with longer travel times are concentrated along the East Coast.
\end{itemize}
}
\end{block}
\end{frame}

\begin{frame}{Objective}
\phantomsection\label{objective}
This research aims to do the following:

\begin{itemize}[<+->]
\tightlist
\item
  Develop a procedure to construct joint confidence intervals for the
  ranks and the ranked parameters when the estimates to be ranked may be
  correlated.
\item
  Evaluate the performance of the proposed approaches under various
  parameter settings.
\item
  Apply the proposed approaches to a real-life example.
\end{itemize}

\note{
\begin{itemize}
  \item For these use cases,
\end{itemize}
}
\end{frame}

\begin{frame}{Definitions and Assumptions}
\phantomsection\label{definitions-and-assumptions}
\begin{itemize}[<+->]
\tightlist
\item
  Define
  \(\hat{\boldsymbol{\theta}}=(\hat{\theta}_1,\hat{\theta}_2,\ldots,\hat{\theta}_K)'\)
  and assume that
  \(\hat{\boldsymbol{\theta}}\sim N(\boldsymbol{\theta},\boldsymbol{\Sigma})\)
  where \(\boldsymbol{\theta}=(\theta_1,\theta_2,\ldots,\theta_K)'\) is
  unknown and \(\boldsymbol{\Sigma}\) is a known \(K \times K\) positive
  definite matrix.
\item
  Note that in the literature on inferences on the ranks, it is
  customary to assume that the variances are known.
\item
  We express \(\boldsymbol{\Sigma}\), where \(\mathbf{R}\) is the
  correlation matrix. \begin{equation}
  \boldsymbol{\Sigma} = \boldsymbol{\Delta}^{1/2} \mathbf{R} \boldsymbol{\Delta}^{1/2}; \quad \boldsymbol{\Delta} = \text{diag} \left\{ \sigma^2_1, \sigma^2_2, \dots, \sigma^2_K \right\}.
  \notag
  \end{equation}
\end{itemize}

\note{
\begin{itemize}
  \item The estimators may be correlated, so the covariance matrix is not necessarily diagonal. We write the covariance matrix in terms of variances and a correlation matrix.
  \item The diagonal elements of $\boldsymbol{\Sigma}$, which are $\sigma^2_k=V(\hat{\theta}_k)$ for $k =1,2, \ldots,K$, are treated as known quantities in practice.
\end{itemize}
}
\end{frame}

\begin{frame}{Procedure}
\phantomsection\label{procedure}
\begin{enumerate}[<+->]
\tightlist
\item
  Derive simultaneous confidence intervals for
  \(\theta_1,\theta_2,\ldots,\theta_K\) of the form \begin{equation}
  \mathfrak{R}_1 = 
  [\hat{\theta}_1 \pm t \times \sigma_1] \times
  [\hat{\theta}_2 \pm t \times \sigma_2] \times
  \cdots \times
  [\hat{\theta}_K \pm t \times \sigma_K].
  \label{eq:rev1}
  \end{equation}
\end{enumerate}

\begin{enumerate}[<+->]
\setcounter{enumi}{1}
\tightlist
\item
  Use the result of Klein et al.~(2020) to get the lower and upper
  bounds on the ranks \(r_k, k=1,2,\ldots,K\).
\end{enumerate}

\note{
\begin{itemize}
  \item bullet 2: Once the confidence intervals in have been obtained, we can then use the result of Klein to get the lower and upper bounds on the ranks $r_k, k=1,2,\ldots,K$. That is, we also get a joint confidence region for $r_1, r_2, . . . , r_K$.
\end{itemize}
}
\end{frame}

\begin{frame}{Proposed methodology to compute the joint confidence
region for the unordered parameters: Algorithm 1}
\phantomsection\label{proposed-methodology-to-compute-the-joint-confidence-region-for-the-unordered-parameters-algorithm-1}
Let the data be represented by
\(\hat{\boldsymbol{\theta}} = \left( \hat \theta_1, \hat \theta_2, \dots, \hat \theta_K \right)'\)
and suppose that \(\boldsymbol{\Sigma}\) is known

\begin{algorithmic}[1]
        \For {$b = 1, 2, \dots, B$}
\uncover<2->{                \State Generate $\hat{\boldsymbol{\theta}}^*_b \sim N_K \left( \hat{\boldsymbol{\theta}}, \boldsymbol{\Sigma}\right)$ and write $\hat{\boldsymbol{\theta}}^*_b = \left( \hat\theta^*_{b1}, \hat\theta^*_{b2}, \dots, \hat\theta^*_{bK} \right)' $}
\uncover<3->{                \State Compute 
                \Statex \begin{minipage}{\linewidth}
                \centering
                $t^*_b = \underset{1 \leq k \leq K}{\max} \Bigg| \frac{\hat\theta^*_{bk} - \hat\theta_{k}}{\sigma_k} \Bigg|$
                \end{minipage}}
        \EndFor
\uncover<4->{        \State Compute the $\left(1-\alpha\right)$-sample quantile of $t^*_1, t^*_2, \dots, t^*_B$, call this $\hat{t}$.}
\uncover<5->{         \State The joint confidence region for $\boldsymbol{\theta} = (\theta_1, \theta_2, \dots, \theta_K)'$ is given by 
        \Statex \begin{minipage}{\linewidth}
    \centering
$\mathfrak{R}_1 = \left[ \hat\theta_1 \pm \hat t \times \sigma_1  \right] \times \left[ \hat\theta_2 \pm \hat t \times \sigma_2  \right] \times \dots \times \left[ \hat\theta_K \pm \hat t \times \sigma_K  \right]$.
    \end{minipage}}
    \end{algorithmic}

\note{
Remarks about bootstrap (Hesterberg,2021):
\begin{itemize}
  \item We plugin the estimator of an unknown parameter to the normal distribution
  \item Bootstrap is implemented by Monte Carlo sampling.
  \item We estimate the distribution of t directly from the data, contrary to using the z-table
  \item Bootstrap distribution is centered at the observed statistic, not the parameter. That is, the mean of the bootstrap estimates is not $\mu$ but $\bar x$. As a result, we do not use the mean of the bootstrap  statistic as a replacement for the original estimator (e.g., bootstrap cannot improve upon $\bar x$) as an estimator for $\mu$.  
  \item Bootstrap is for estimating only the SE (it is only use to estimate parameter for some, e.g. quantiles)
\end{itemize}
}
\end{frame}

\begin{frame}{Algorithm 1:}
\phantomsection\label{algorithm-1}
We want our joint confidence region to satisfy the probability
condition:

\begin{align}
P\left( \hat{\theta}_k-t \cdot \sigma_k \leq  \theta_k \leq  \hat{\theta}_k + t \cdot \sigma_k, \,\, \forall\; k=1,2,\ldots,K \right)  =1-\alpha \notag \\
\uncover<2->{P\left( -t \cdot \sigma_k \leq  \theta_k - \hat{\theta}_k \leq t \cdot \sigma_k, \,\, \forall\; k=1,2,\ldots,K \right)  =1-\alpha} \notag \\
\uncover<3->{P\left( t \geq  \frac{\hat{\theta}_k-\theta_k}{\sigma_k} \geq -t, \,\, \forall\; k=1,2,\ldots,K \right)  =1-\alpha} \notag \\
\uncover<4->{P\left( \left| \dfrac{\hat{\theta}_k-\theta_k}{\sigma_k} \right| \le t, \,\, \forall\; k=1,2,\ldots,K \right) =1-\alpha} \notag \\
\uncover<5->{\Longleftrightarrow P\left( \max_{k=1,2,\ldots,K} \left| \dfrac{\hat{\theta}_k-\theta_k}{\sigma_k} \right| \le t \right) =1-\alpha
} \notag
\end{align}

\note{
\begin{itemize}
  \item Bootstrap principle: Sample acts as a new population; bootstrap sample take the place of the sample 
\end{itemize}
}
\end{frame}

\begin{frame}{Proposed methodology to compute a joint confidence region
for the ordered parameters}
\phantomsection\label{sec:nonrank}
\begin{minipage}{1.0\textwidth}
\begin{algorithmic}[1]
    \For {$b = 1, 2, \dots, B$}
\uncover<2->{        \State
            Generate $\hat{\boldsymbol{\theta}}^*_b = \left( \hat{\theta}^*_{b1}, \hat{\theta}^*_{b2}, \dots, \hat{\theta}^*_{bK} \right)' \sim N_K \left( \boldsymbol{\hat \theta}, \boldsymbol {\Sigma} \right)$ and let $\hat{\theta}^*_{b(1)}, \hat{\theta}^*_{b(2)}, \dots, \hat{\theta}^*_{b(K)}$ be the corresponding ordered values}
\uncover<3->{        \State
        Compute $\hat\sigma^*_{b(k)}$ using:
        \Statex \qquad • asymptotic variance definition
        \Statex \qquad • second-level bootstrap}
\uncover<4->{        \State
            Compute
\Statex
\begin{center}
$t^*_b = \underset{1 \leq k \leq K}{\max} \Bigg| \frac{\hat\theta^*_{b(k)} - \hat\theta_{(k)}}{\hat\sigma^*_{b(k)}} \Bigg|$
\end{center}}
    \EndFor
\uncover<5->{    \State Compute the $\left(1-\alpha\right)$-sample quantile of $t^*_1, \dots, t^*_B$, call this $\hat{t}$.}
\uncover<6->{    \State The joint confidence region of $\theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}$ is given by
\Statex
\begin{center}
    $\mathfrak{R}_2 = \left[ \hat\theta_{(1)} \pm \hat t \times \hat\sigma_{(1)}  \right] \times \left[ \hat\theta_{(2)} \pm \hat t \times \hat\sigma_{(2)}  \right] \times \dots \times \left[ \hat\theta_{(K)} \pm \hat t \times \hat\sigma_{(K)}  \right]$
\end{center}}
    \end{algorithmic}
\end{minipage}

\note{
\begin{itemize}
  \item We can say we are 95 percent confident that the smallest parameter up to the largest parameter falls between the calculated bounds.
\end{itemize}
}
\end{frame}

\begin{frame}{Algorithm 2: Asymptotic Definition of Variance}
\phantomsection\label{algorithm-2-asymptotic-definition-of-variance}
\begin{itemize}[<+->]
\tightlist
\item
  This uses results from Chen (1976) and Dudewicz (1972) to obtain an
  expression of the asymptotic variance of \(\hat{\theta}_{(k)}\)
\end{itemize}

\(\hat\sigma^*_{b(k)} = \sqrt{\left[\text{kth ordered value among} \ \left\{ \hat{\theta}^{*2}_{b1} + \sigma_1^2, \dots, \hat{\theta}^{*2}_{bK} + \sigma_K^2 \right\}\right] - \hat {\theta}^{*2}_{(k)}}\)

\begin{itemize}[<+->]
\tightlist
\item
  In \(\mathfrak{R}_2\),
  \(\hat\sigma_{(k)} = \sqrt{\text{kth ordered value among} \ \left\{ \hat{\theta}^{2}_{1} + \sigma_1^2, \hat{\theta}^{2}_{2} + \sigma_2^2, \dots, \hat{\theta}^{2}_{K} + \sigma_K^2 \right\} - \hat {\theta}^{2}_{(k)}}\)
\end{itemize}
\end{frame}

\begin{frame}{Algorithm 3: Variance from Second-Level Bootstrap}
\phantomsection\label{algorithm-3-variance-from-second-level-bootstrap}
\begin{itemize}[<+->]
\tightlist
\item
  Second-level bootstrap algorithm
\end{itemize}

\begin{algorithmic}[1]
            \For {$c = 1, 2, \dots, C$}
\uncover<2->{                \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent} Generate $\hat{\boldsymbol{\theta}}^{**}_{bc} = \left( \hat{\theta}^{**}_{bc1}, \hat{\theta}^{**}_{bc2}, \dots, \hat{\theta}^{**}_{bcK} \right) \sim N_K \left( \hat{\boldsymbol{\theta}}_b^*, \boldsymbol {\Sigma} \right)$ and let $\hat{\theta}^{**}_{bc(1)}, \hat{\theta}^{**}_{bc(2)}, \dots, \hat{\theta}^{**}_{bc(K)}$ be the corresponding ordered values of $\hat{\theta}^{**}_{bc1}, \hat{\theta}^{**}_{bc2}, \dots, \hat{\theta}^{**}_{bcK}$
                \end{minipage}}
\uncover<3->{                \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent} Compute
                $\displaystyle \hat{\sigma}^*_{b(k)} = \sqrt{\frac{\sum^C_{c=1} \left( \hat \theta^{**}_{bc(k)} - \bar {\hat\theta}^{**}_{b \cdot (k)} \right)^2}{C-1}}, \quad \bar {\hat\theta}^{**}_{b\cdot(k)} = \frac{1}{C} \sum^C_{c=1} {\hat\theta}^{**}_{bc(k)}$
                \end{minipage}}
                \EndFor
    \end{algorithmic} 
\uncover<4->{ In $\mathfrak{R}_2$, $\displaystyle \hat \sigma_{(k)} = \sqrt{ \frac{\sum^B_{b=1} \left( \hat \theta^*_{b(k)} - \bar {\hat\theta}^*_{\cdot (k)} \right)^2}{B-1}}, \quad \bar {\hat\theta}^*_{\cdot(k)} = \frac{1}{B} \sum^B_{b=1} {\hat\theta}^*_{b(k)}$}

\note{
\begin{itemize}
  \item unavailable SE formula - we would need to compute a bootstrap estimate for the standard error for each bootstrap sample.
  \item involves taking second level, nested bs samples that will be used to estimate se.
  \item 
\end{itemize}
}
\end{frame}

\begin{frame}{Evaluation Algorithm}
\phantomsection\label{evaluation-algorithm}
For given values of \(\boldsymbol{\Sigma}\) and
\(\theta_1, \theta_2, \dots, \theta_K\) (with corresponding
\(\theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}\) for ordered
parameters)

\begin{algorithmic}[1] % Start algorithmic block
            \For {$\text{replications} = 1, 2, \dots, 5000$}
\uncover<2->{            \State Generate $\hat{\boldsymbol{\theta}} \sim N_K(\boldsymbol{\theta}, \boldsymbol{\Sigma})$}
\uncover<3->{            \State Compute the confidence region $\mathfrak{R}_1$ for the unordered parameters using Algorithm 1 and the confidence region for the ordered parameters $\mathfrak{R}_2$ using Algorithms 2 and 3.}
\uncover<4->{            \State For the unordered parameters, check if $\left( \theta_1, \theta_2, \dots, \theta_K\right) \in \mathfrak{R}_1$ and compute $T_1, T_2$, and $T_3$. For the ordered parameters, check if $\left( \theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}\right) \in \mathfrak{R}_2$}
        \EndFor
\uncover<3->{    \State Compute the proportion of times that the condition in line 4 is satisfied and the average of $T_1, T_2$, and $T_3$.}
    \end{algorithmic}
\end{frame}

\begin{frame}{Measures of tightness}
\phantomsection\label{measures-of-tightness}
\begin{equation}
  T_1 = \frac{1}{K} \sum^K_{k=1} \Big | \Lambda_{Ok} \Big|
  \notag
\end{equation} \begin{equation}
  T_2 = \prod^K_{k=1} \Big | \Lambda_{Ok} \Big|
  \notag
\end{equation}

\begin{equation}
  T_3 = 1 - \frac{OP}{K^2}; OP = K + \sum^K_{k=1} \big | \Lambda_{Ok} \big|
  \notag
\end{equation}

\note{
\begin{itemize}
  \item Moreover, the tightness of the joint confidence region that results from Algorithm 1 is assessed using three summary measures: the arithmetic mean (\(T_1\)), geometric mean (\(T_2\)), and the metric \(T_3\) introduced by Wright (2025)
  \item $OP$ denotes the total number of occupied positions in a joint confidence region out of the total number of positions $K^2$; or the sum of the differences between the upper and lower bound of the simultaneous rank intervals added by 1, for each population $k$. 
  \item Higher values of $T_1$ and $T_2$ indicate wider confidence intervals and are therefore less desirable, whereas higher values of $T_3$ are preferable. $T_3$ can range from 0, indicating no tightness, to $\frac{K-1}{K}$, implying the confidence region only contains the estimated ranking which is likely the true ranking.
\end{itemize}
}
\end{frame}

\begin{frame}{Simulation settings}
\phantomsection\label{simulation-settings}
The following settings are considered for
\(K = \{10, 20, 30, 40, 50\}\). Each \(K\) has a set of corresponding
variances \(\sigma^2_1, \sigma^2_2,\ldots,\sigma^2_K\). A nominal level
of \(1-\alpha=0.95\) will be used.

\begin{center}
\begin{tabular}{ |c|c| }
\hline
$\boldsymbol{\theta}$ & Correlation matrix \\
\hline \hline
low variability & $\mathbf{R}_{\text{eq}},\, \mathbf{R}_{\text{block}}$ \\
medium variability & $\mathbf{R}_{\text{eq}},\, \mathbf{R}_{\text{block}}$ \\  
high variability & $\mathbf{R}_{\text{eq}},\, \mathbf{R}_{\text{block}}$ \\
\hline
\end{tabular}
\end{center}

\note{
\begin{itemize}
  \item We assume certain correlation structures among the $\hat{\theta}$s.  
  \item Equicorrelation is considered for simplicity.  
\end{itemize}
}
\end{frame}

\begin{frame}{Correlation Structures: Equicorrelation}
\phantomsection\label{correlation-structures-equicorrelation}
\begin{itemize}[<+->]
\tightlist
\item
  This assumes that the \(k\) variables are equally correlated, i.e.,
  that \(\rho_{jk}=\rho\) where \(\rho \in [-1,1]\) for
  \(j \neq k \in \{1, \dots, K\}\). \begin{equation}
  \mathbf{R}_{\text{eq}} = \left( 1-\rho \right) \mathbf{I}_K + \rho \boldsymbol{1}_K \boldsymbol{1}'_K = 
  \begin{bmatrix}
  1 & \rho & \cdots & \rho \\
  \rho & 1 & \cdots & \rho \\
  \vdots & \vdots & \ddots & \vdots \\
  \rho & \rho & \cdots & 1
  \end{bmatrix}_{K \times K}
  \notag
  \end{equation}
\end{itemize}

\note{
\begin{itemize}
  \item We assume certain correlation structures among the $\hat{\theta}$s.  
  \item Equicorrelation is considered for simplicity.  
\end{itemize}
}
\end{frame}

\begin{frame}{Correlation Structures: Block correlation}
\phantomsection\label{correlation-structures-block-correlation}
\begin{itemize}[<+->]
\tightlist
\item
  The full block correlation matrix can be expressed as\\
  \begin{equation}
  \mathbf{R}_{\text{block}} = 
  \begin{bmatrix}
  \mathbf{R}_{eq,1} & \mathbf{C}_{12} & \cdots & \mathbf{C}_{1G} \\
  \mathbf{C}_{21} & \mathbf{R}_{eq,2} & \cdots & \mathbf{C}_{2G} \\
  \vdots & \vdots & \ddots & \vdots \\
  \mathbf{C}_{G1} & \mathbf{C}_{G2} & \cdots & \mathbf{R}_{eq,G}
  \end{bmatrix}_{K \times K}
  \notag
  \end{equation}
\item
  \(\mathbf{C}_{g'g} = \mathbf{C}_{gg'} = \rho_{gg'}\boldsymbol{1}_{n_g} \boldsymbol{1}'_{n_g}\)
  where \(g\neq g' \in \{1, \dots, G\}\)
\end{itemize}

\note{
\begin{itemize}
  \item Useful in the context of pre-election surveys
  \item In a block correlation matrix $\mathbf{R}_{block}$ with $G$ blocks, each diagonal block represents an equicorrelation structure within group $g$, denoted by
\begin{equation}
  \mathbf{R}_{\text{eq,g}} = \left( 1-\rho_{g} \right) \mathbf{I}_{n_g} + \rho_{g} \boldsymbol{1}_{n_g} \boldsymbol{1}'_{n_g} \notag
\end{equation}
where $\rho_{g}$ is the within-block correlation and $n_g$ is the number of variables in block $g$ such that $\sum_{g=1}^G n_g = K$.  
  \item The off-diagonal blocks capture between-block correlations, represented by  $\mathbf{C}_{g'g} = \mathbf{C}_{gg'} = \rho_{gg'}\boldsymbol{1}_{n_g} \boldsymbol{1}'_{n_g}$ where $g\neq g' \in \{1, \dots, G\}$
\end{itemize}
}
\end{frame}

\begin{frame}{Correlation Structures: Distance-based correlation}
\phantomsection\label{correlation-structures-distance-based-correlation}
\begin{itemize}[<+->]
\tightlist
\item
  Spatial dependence can be modeled using a stationary Matérn
  correlation function, which for two locations \(\mathbf{s}_i\) and
  \(\mathbf{s}_j\) is expressed as \begin{equation}
  \rho_{\text{matern}} = \frac{2^{1-\nu}}{\Gamma(\nu)} (\kappa \;\Vert \;\mathbf{s}_i - \mathbf{s}_j \; \Vert)^\nu K_\nu  (\kappa \;\Vert \;\mathbf{s}_i - \mathbf{s}_j \; \Vert)
  \notag
  \end{equation} where \(\Vert \cdot \Vert\) denotes the Euclidean
  distance and \(K_\nu\) is the second kind of the modified Bessel
  function. It has a scale parameter \(\kappa > 0\) and a smoothness
  parameter \(\nu > 0\).
\end{itemize}

\note{
\begin{itemize}
  \item  Useful in the mean travel time from the study of Klein et al. (2020).
\end{itemize}
}
\end{frame}

\begin{frame}{Summary and Next steps}
\phantomsection\label{summary-and-next-steps}
\begin{itemize}[<+->]
\tightlist
\item
  Proposed contribution: Develop a procedure to construct joint
  confidence intervals for the ranks and the ranked parameters when the
  estimates to be ranked may be correlated.
\item
  Next steps:

  \begin{itemize}[<+->]
  \tightlist
  \item
    Complete simulation studies
  \item
    Apply the proposed approach to a real-life example
  \end{itemize}
\end{itemize}

\vspace{1cm}

\uncover<6->{
Thank you.
}
\end{frame}

\end{document}
