## Joint confidence region for an overall ranking

@klein proposed an approach for quantifying overall rank uncertainty following the estimation of respondents' average travel time to work in each $K$ sampled geographical area. In their paper, rank for the $k$th population is defined as 

\begin{equation}
  r_k = \sum^K_{j=1} I(\theta_j \leq \theta_k) = 1 + \sum_{j:j \neq k} I(\theta_j \leq \theta_k), \qquad \text{for} \; k = 1, \dots, K
  \label{eq:rank}
\end{equation}

Meanwhile, the estimated overall ranking is computed from the estimates $\hat{\theta}_1, \dots, \hat{\theta}_K$, and expressed as $\left(\hat{r}_1, \dots, \hat{r}_K\right)$, where

\begin{equation}
  \hat r_k = 1 + \sum_{j:j \neq k} I(\hat \theta_j \leq \hat \theta_k), \qquad \text{for} \; k = 1, \dots, K
  \label{eq:estimatedrank}
\end{equation}

The true values, $\theta_1, \dots, \theta_K$ are unknown. For this, they assumed that for each $k \in \left\{1, 2, \dots, K\right\}$, there exists $L_k$ and $U_k$ such that


\begin{equation}
  \theta_k \in \left( L_k, U_k \right)
  \label{eq:theta_in}
\end{equation}
and defined the following:

\begin{equation}
    \left.
        \begin{array}{cc}
                I_k = \left\{ 1, 2, \dots, K \right\} - \left\{k \right\}, \\
                \Lambda_{Lk} = \left\{ j \in I_k : U_j \leq L_k \right\}, \\
                \Lambda_{Rk} = \left\{ j \in I_k : U_k \leq L_j \right\}, \\
                \Lambda_{Ok} = \left\{ j \in I_k:U_j > L_k \ \text{and} \ U_k > L_j \right\} = I_k - \left\{ \Lambda_{Lk} \cup \Lambda_{Rk} \right\}
    	\end{array}
    \right\}
  \label{eq:conf_set}
\end{equation}
Equation \ref{eq:conf_set} can likewise be expressed in words as follows:

1. $j \in \Lambda_{Lk} \leftrightarrow \left(L_j, U_j\right) \cap \left(L_k, U_k\right) = \emptyset$ and $\left(L_j, U_j\right)$ lies to the left of $\left(L_k, U_k\right)$;
2. $j \in \Lambda_{Rk} \leftrightarrow \left(L_j, U_j\right) \cap \left(L_k, U_k\right) = \emptyset$ and $\left(L_j, U_j\right)$ lies to the right of $\left(L_k, U_k\right)$;
3. $j \in \Lambda_{Ok} \leftrightarrow \left(L_j, U_j\right) \cap \left(L_k, U_k\right) \neq \emptyset$
4. $\Lambda_{Lk}, \Lambda_{Rk},$ and $\Lambda_{Ok}$ are mutually exclusive, and $\Lambda_{Lk} \cup \Lambda_{Rk} \cup \Lambda_{Ok} = I_k$    
The above implies that for each $k \in \left\{1, 2, \dots, K\right\}$,

\begin{equation}
  r_k \in 
  \left\{ 
  \lvert \Lambda_{Lk} \rvert + 1,  
  \lvert \Lambda_{Lk} \rvert + 2,
  \lvert \Lambda_{Lk} \rvert + 3,
  \dots,
  \lvert \Lambda_{Lk} \rvert + \lvert \Lambda_{Ok} \rvert + 1
  \right\}
  \label{eq:conf_set_rk}
\end{equation}
Equation \ref{eq:conf_set_rk} demonstrates that a smaller $\lvert \Lambda_{Ok} \rvert$ results in smaller difference between $U_k$ and $L_k$. Collectively, for all $k$, this yields narrower confidence intervals for the overall ranks, which is desirable.

They also assumed a conservative confidence region whose joint coverage probability is at least as large as the nominal level, $1-\alpha$, as shown in Equation \ref{eq:joint_cov}.

\begin{equation}
  P\left[ \bigcap^K_{k=1} \left\{ \theta_k \in \left(L_k, U_k\right) \right\} \right] \geq 1-\alpha
  \label{eq:joint_cov}
\end{equation}
This yields the joint confidence set for the overall ranking, as defined in Equation \ref{eq:klein_jcs}, which they showed to also have a joint probability of at least $1-\alpha$.

\begin{equation}
  \left\{ 
  \left( r_1, \dots, r_K\right):
  r_k \in 
  \left\{ 
    \lvert \Lambda_{Lk} \rvert + 1,  
    \lvert \Lambda_{Lk} \rvert + 2,
    \lvert \Lambda_{Lk} \rvert + 3,
    \dots,
    \lvert \Lambda_{Lk} \rvert + \lvert
    \;
    \text{for}
    \;
    k = 1, 2, \dots, K
  \right\}
  \right\}
  \label{eq:klein_jcs}
\end{equation}

In line with this, they presented a proof demonstrating that if $(L_1,U_1),\dots,(L_K,U_K)$ are constructed such that the estimator $\hat{\theta}_k \in (L_k, U_k) \; \forall k \in \{1, 2, \dots, K\}$, then the estimated ranking $(\hat r_1, \hat r_2, \dots,\hat r_K)$ lies within the joint confidence region defined in Equation \ref{eq:klein_jcs} with probability 1.

They also noted that the joint confidence region in \ref{eq:klein_jcs} contains more than one possible
overall ranking unless the values of $\theta_k$ differ from each other such that $(L_k, U_k) \cap (L_{k'}, U_{k'}) = \emptyset, \; \forall \; k\neq k'$. This implies that the unique overall ranking arises only from the narrowest attainable joint confidence region and it is the estimated ranking, $(\hat r_1, \hat r_2, \dots,\hat r_K)$.

## Joint confidence intervals for $\theta_k$s

@klein used individual confidence intervals of the form $\hat \theta_k \pm z_{\alpha/2} SE_k^2$, with $\hat \theta_k \sim N(\theta_k, SE_k)$ for $k \in \left\{1, 2, \dots, K\right\}$, where $\theta_1, \theta_2, \dots \theta_k$ are unknown and $SE_1, SE_2, \dots, SE_k$ are known. It was noted that ${MOE_k} = {z_{\alpha/2} \times SE_k}$ where $SE_k = \frac{\sigma_k}{\sqrt{n}}$.

The first one can be traced from Theorem 1 of @sidak which states that for a vector of random variables of dimension $K$, $\mathbf{X} = (X_1, X_2, \dots, X_K)$, with $\mathbf{X} \sim N_K\!\left(\mathbf{0}, \Sigma \right)$ and having an arbitrary correlation matrix $\mathbf{R} = \left\{ \rho_{kk'} \right\}_{k, k' =1}^K$,

\begin{align}
P(\lvert X_1\rvert \leq c_1, \; 
\dots,
\lvert X_K\rvert \leq c_K) &\geq \notag \\
&P(\lvert X_1\rvert \leq c_1) \times
P(\lvert X_2 \rvert \leq c_2, \dots, \lvert X_K \rvert \leq c_K), \notag \\ &\text{for any positive numbers}\; c_1, c_2, \dots, c_K 
\end{align}
He showed by induction that under the assumptions of Theorem 1,

\begin{equation}
P(\lvert X_1\rvert \leq c_1, \; 
\dots,
\lvert X_K\rvert \leq c_K) \geq 
\prod^K_{k=1} P\left( \lvert X_k \rvert \leq c_k\right)
\label{eq:corollary1}
\end{equation}
For the simultaneous confidence intervals used by Klein, @sidak considered a random sample of $n$ vectors of $\mathbf{Y}_i = \left( Y_{i1}, Y_{i2}, \dots, Y_{iK}\right)',\; i=1, \dots, n$ where $Y_{ik} \sim N(\mu_k, \sigma_k^2)$ with unknown $\mu_k$ and known $\sigma_k^2$ and stated that

\begin{equation}
X_k = \frac{\left( \hat{\theta}_k - \mu_k\right)}{\sigma_k \; \diagup \sqrt{n}} \sim N\!(0, 1), \quad k =1, \dots, K
\label{eq:standardized}
\end{equation}
where

\begin{equation}
\hat{\theta}_k = \bar {Y}_k = n^{-1} \sum^n_{i=1} Y_{ik}
\end{equation}
satisfies the requirements of Theorem 1. Hence, when constructing a simultaneous confidence interval for $\theta_k = \mu_k,\; \forall k \in \{1, 2, \dots, K\}$ with $(1-\alpha)$ confidence level, it follows from \ref{eq:corollary1} and \ref{eq:standardized} that, 

\begin{align}
\prod^K_{k=1} P\left( \lvert X_k \rvert \leq c_k\right) &=
\prod^K_{k=1} P\left( \hat{\theta}_k-c_k \cdot \frac{\sigma}{\sqrt{n}} \leq  \theta_k \leq  \hat{\theta}_k + c_k \cdot \frac{\sigma}{\sqrt{n}} \right) \\
&=\prod^K_{k=1} P\left( \hat{\theta}_k-c_k \cdot SE_k \leq  \theta_k \leq  \hat{\theta}_k + c_k \cdot SE_k \right) \notag \\
&=1-\alpha \notag
\end{align}
and assuming independence, even when dependence is actually present, will always result in a confidence level at least as large as $1-\alpha$. $c_k$ can be selected so that $c_1 = \dots = c_K$ and $(1 - \gamma)^K = 1 - \alpha$, where $\gamma$ is the individual confidence level, are satisfied. Under these conditions, a two-sided $100(1-\gamma) \%$ confidence interval for the parameter $\theta_k = \mu_k$ is given by

\begin{equation}
  I_{k(ind)} =
  \left(
  \hat \theta_k - z_{\gamma/2}SE_k,
  \;
  \hat \theta_k + z_{\gamma/2}SE_k
  \right),
  \qquad
  \text{for}\;k \in \{1, 2, \dots, K\}
  \label{eq:ind}
\end{equation}
where 
\begin{equation}
z_{\gamma/2} = \Phi^{-1}\left(1-\frac{\gamma}{2}\right) = \Phi^{-1}\left(1-\frac{1 - (1 - \alpha)^{1/K}}{2}\right)
\end{equation}


The Bonferroni correction results in a conservative joint coverage for $\theta_1, \theta_1, \dots, \theta_K$ of at least $1-\alpha$. Intervals are as defined in Equation  \ref{eq:bonf}.

\begin{equation}
  \left(
  \hat \theta_k - z_{(\alpha/K)/2}SE_k,
  \;
  \hat \theta_k + z_{(\alpha/K)/2}SE_k
  \right),
  \qquad
  \text{for}\;k=1,2,\dots,K
  \label{eq:bonf}
\end{equation}


With the same assumptions, @jelle used Tukey's pairwise comparison procedure to come up with their $\left( 1-\alpha \right)$ joint confidence intervals for ranks defined in Equation \ref{eq:jelle}. They showed this to yield uniformly narrower intervals than that of Klein's approach, for the case when $SE$s are equal.


\begin{equation}
  \left(
  1 + \#\left\{ j: y_i - y_j - q_{1-\alpha}\sqrt{SE^2_i + \sigma^2_j} > 0 \right\},
  \;
  n - \#\left\{ j: y_i - y_j + q_{1-\alpha}\sqrt{SE^2_i + \sigma^2_j} < 0 \right\}
  \right),
  \label{eq:jelle}
\end{equation}
where $\gamma = 1 - (1-\alpha)^{\frac{1}{K}}$.

@zhang analyzed U.S. age-adjusted cancer incidence and mortality rates across states and counties by computing individual and overall simultaneous confidence intervals for age-adjusted health index using the Monte Carlo method. Because many health conditions are age-dependent, they used age-adjusted rates to minimize the confounding effect of age differences when comparing different population groups. They also extended their method to handle cases where only the rates and confidence intervals are available, aligning it more closely with the approaches of @klein and @jelle.



## Use case

*(literature on importance for accounting for correlation)*


https://mgimond.github.io/Spatial/spatial-autocorrelation.html

https://cran.r-project.org/web/packages/simstudy/vignettes/corelationmat.html

