This section introduces the proposed methodologies to obtain joint confidence intervals that can be used to quantify uncertainty for the unknown overall true ranking. It addresses the scenario when the estimates of the parameters being ranked are correlated to certain degrees. Section \ref{sec:proposed-methodology-to-compute-simultaneous-confidence-intervals-for-the-unordered-parameters} develops the procedure used to compute the joint confidence region for $\theta_1, \theta_2, \dots, \theta_K$. These include a non-rank and rank-based methods. Section \ref{sec:rankbased}, on the other hand, develops the procedure to compute the joint confidence region for $\theta_{(1)},\theta_{(2)},\ldots,\theta_{(K)}$. Section 3.3 discusses some possible correlation structures to be considered for the estimates. Sections \ref{sec:evaluation} and \ref{sec:simulation-settings} discuss how to evaluate the proposed methodology and the simulation settings to be used.

## Proposed methodology to compute the joint confidence region for the unordered parameters {#sec:proposed-methodology-to-compute-simultaneous-confidence-intervals-for-the-unordered-parameters}


In this section, we adopt the notations defined in Section \ref{sec:ranking-problem} and \ref{sec:kleins-joint-confidence-region-for-overall-ranking-uncertainty}. Moreover, we define $\hat{\boldsymbol{\theta}}=(\hat{\theta}_1,\hat{\theta}_2,\ldots,\hat{\theta}_K)'$ and assume that $\hat{\boldsymbol{\theta}}\sim N(\boldsymbol{\theta},\boldsymbol{\Sigma})$ where $\boldsymbol{\theta}=(\theta_1,\theta_2,\ldots,\theta_K)'$ is unknown and $\boldsymbol{\Sigma}$ is a known $K \times K$ positive definite matrix. The diagonal elements of $\boldsymbol{\Sigma}$ are $\sigma^2_1,\ldots,\sigma^2_K$. We note that in the literature on inferences on the ranks, it is customary to assume that the variances are known. As previously mentioned, the setup in this thesis allows the estimates to be correlated, which is in contrast with that of @klein, which assumes independence among the estimates. In other words, in this thesis, the covariance matrix $\boldsymbol{\Sigma}$ need not be a diagonal matrix. Similar to the study of @klein, knowledge of the sampling design and estimation methodology for each population is not required; we shall first derive simultaneous confidence intervals for $\theta_1,\theta_2,\ldots,\theta_K$ of the form 

\begin{equation}
\mathfrak{R}_1 = 
[\hat{\theta}_1 \pm t \times \sigma_1] \times
[\hat{\theta}_2 \pm t \times \sigma_2] \times
\cdots \times
[\hat{\theta}_K \pm t \times \sigma_K].
  \label{eq:rev1}
\end{equation}

We want the joint confidence region in (\ref{eq:rev1}) to satisfy the following probability condition:

\begin{equation}
 P\left( \hat{\theta}_k-t \cdot \sigma_k \leq  \theta_k \leq  \hat{\theta}_k + t \cdot \sigma_k, \,\, \forall\; k=1,2,\ldots,K \right)  =1-\alpha.
\end{equation}

Equivalently, we require

\begin{equation}
 P\left( \max_{k=1,2,\ldots,K} \left| \dfrac{\hat{\theta}_k-\theta_k}{\sigma_k} \right| \le t \right)  =1-\alpha. 
\end{equation}


We use the parametric bootstrap to estimate the quantile $t$ that will be used to construct the confidence intervals while controlling the coverage to be around the nominal level. In implementing the parametric bootstrap, we sample from the multivariate normal distribution with $\hat{\boldsymbol{\theta}}$ and $\boldsymbol{\Sigma}$ as mean and variance, respectively. The idea is also conceptually similar to that of @mogstadt23 who use resampling to obtain the quantile in a different context. Algorithm \ref{alg:nonrank_ci} describes the procedure to compute the joint confidence region based on unordered estimates.

Once the confidence intervals in (\ref{eq:rev1}) have been obtained, we can then use the result of @klein in (\ref{eq:joint_cov2}) to get the lower and upper bounds on the ranks $r_k, k=1,2,\ldots,K$. That is, we also get a joint confidence region for $r_1, r_2, . . . , r_K$.


\begin{algorithm}[H]
\fontsize{15pt}{18pt}\selectfont
    \caption{Computing the joint confidence region for the unordered parameters} 
    \label{alg:nonrank_ci}
    Let the data be represented by $\hat{\boldsymbol{\theta}} = \left( \hat \theta_1, \hat \theta_2, \dots, \hat \theta_K \right)'$ and suppose that $\boldsymbol{\Sigma}$ is known
    \begin{algorithmic}[1]
        \For {$b = 1, 2, \dots, B$}
                \State Generate $\hat{\boldsymbol{\theta}}^*_b \sim N_K \left( \hat{\boldsymbol{\theta}}, \boldsymbol{\Sigma}\right)$ and write $\hat{\boldsymbol{\theta}}^*_b = \left( \hat\theta^*_{b1}, \hat\theta^*_{b2}, \dots, \hat\theta^*_{bK} \right)' $
                \State Compute 
                \Statex \begin{minipage}{\linewidth}
                \centering
                $t^*_b = \underset{1 \leq k \leq K}{\max} \Bigg| \frac{\hat\theta^*_{bk} - \hat\theta_{k}}{\sigma_k} \Bigg|$
                \end{minipage}
        \EndFor
        \State Compute the $\left(1-\alpha\right)$-sample quantile of $t^*_1, t^*_2, \dots, t^*_B$, call this $\hat{t}$.
        \State The joint confidence region for $\boldsymbol{\theta} = (\theta_1, \theta_2, \dots, \theta_K)'$ is given by 
        \Statex \begin{minipage}{\linewidth}
    \centering
$\mathfrak{R}_1 = \left[ \hat\theta_1 \pm \hat t \times \sigma_1  \right] \times \left[ \hat\theta_2 \pm \hat t \times \sigma_2  \right] \times \dots \times \left[ \hat\theta_K \pm \hat t \times \sigma_K  \right]$.
    \end{minipage}
    \end{algorithmic} 
\end{algorithm}

## Proposed methodology to compute a joint confidence region for the ordered parameters {#sec:rankbased}

We shall also be proposing an approach to compute simultaneous confidence intervals for the ordered parameters. Suppose that for the parameters $\theta_1,\ldots,\theta_K$, the corresponding ordered values are $\theta_{(1)},\ldots,\theta_{(K)}$.  Similarly, let $\hat{\theta}_{(1)},\ldots,\hat{\theta}_{(K)}$ be the ordered estimates. We now derive a joint confidence region for these ordered values, and set the region to be of the following form:

\begin{equation}
\mathfrak{R}_2=
[\hat{\theta}_{(1)} \pm t \times \sigma_{(1)}] \times
[\hat{\theta}_{(2)} \pm t \times \sigma_{(2)}] \times
\cdots \times
[\hat{\theta}_{(K)} \pm t \times \sigma_{(K)}],
\label{eq:rev2}
\end{equation}
where $\sigma_{(k)}=\sqrt{V\left(\hat{\theta}_{(k)}\right)}$. The confidence region in (\ref{eq:rev2}) is computed such that the following condition holds:

\begin{equation}
 P\left( \hat{\theta}_{(k)}-t \cdot \sigma_{(k)} \leq  \theta_{(k)} \leq  \hat{\theta}_{(k)} + t \cdot \sigma_{(k)}, \,\, \forall k=1,2,\ldots,K \right)  =1-\alpha,
\label{eq:rev3}
\end{equation}
which is equivalent to

\begin{equation}
 P\left( \max_{k=1,2,\ldots,K} \left| \dfrac{\hat{\theta}_{(k)}-\theta_{(k)}}{\sigma_{(k)}} \right| \le t \right)  =1-\alpha,
\label{eq:rev4}
\end{equation}
and we estimate $t$, which in (\ref{eq:rev4}) is the $(1-\alpha)$-quantile of the distribution of $\max_{k} \left| \dfrac{\hat{\theta}_{(k)}-\theta_{(k)}}{\sigma_{(k)}} \right|$, via a suitable parametric bootstrap. Since $\sigma_{(k)}$ is not known, we estimate its value. We present two approaches to estimate $\sigma_{(k)}$. The first uses results from @chen and @dudewicz to obtain an expression of the asymptotic variance of $\hat{\theta}_{(k)}$ as follows:
\begin{equation}
V(\hat{\theta}_{(k)})= \text{kth ordered value among} \ \left\{ \theta^{2}_{1} + \sigma_1^2, \theta^{2}_{2} + \sigma_2^2, \dots, \theta^{2}_{K} + \sigma_K^2 \right\} - \theta^{2}_{(k)}.
\label{eq:rev5}
\end{equation}
Consequently, we get an estimate of the asymptotic variance of $\hat{\theta}_{(k)}$, given by:
\begin{equation}
\widehat{V(\hat{\theta}_{(k)})}= \text{kth ordered value among} \ \left\{ \hat{\theta}^{2}_{1} + \sigma_1^2, \hat{\theta}^{2}_{2} + \sigma_2^2, \dots, \hat{\theta}^{2}_{K} + \sigma_K^2 \right\} - \hat {\theta}^{2}_{(k)}.
\label{eq:rev6}
\end{equation}

Algorithm \ref{alg:rank_asymp} describes the procedure to compute the joint confidence region in (\ref{eq:rev2}) using this approach.

\begin{algorithm}[H]
    \caption{Computing the joint confidence region for the ordered parameters using the estimated asymptotic variance} 
    \label{alg:rank_asymp}
    \begin{algorithmic}[1]
    \For {$b = 1, 2, \dots, B$}
        \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent}
            Generate $\hat{\boldsymbol{\theta}}^*_b = \left( \hat{\theta}^*_{b1}, \hat{\theta}^*_{b2}, \dots, \hat{\theta}^*_{bK} \right)' \sim N_K \left( \boldsymbol{\hat \theta}, \boldsymbol {\Sigma} \right)$ and let $\hat{\theta}^*_{b(1)}, \hat{\theta}^*_{b(2)}, \dots, \hat{\theta}^*_{b(K)}$ be the corresponding ordered values 
        \end{minipage}
        \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent}
            Compute 
                \Statex \begin{minipage}{\linewidth}
                \centering
                $\hat\sigma^*_{b(k)} = \sqrt{\left[\text{kth ordered value among} \ \left\{ \hat{\theta}^{*2}_{b1} + \sigma_1^2, \hat{\theta}^{*2}_{b2} + \sigma_2^2, \dots, \hat{\theta}^{*2}_{bK} + \sigma_K^2 \right\}\right] - \hat {\theta}^{*2}_{(k)}}$
                \end{minipage}
        \end{minipage}
        \State Compute 
                $t^*_b = \underset{1 \leq k \leq K}{\max} \Bigg| \frac{\hat\theta^*_{b(k)} - \hat\theta_{(k)}}{\hat\sigma^*_{b(k)}} \Bigg|$
    \EndFor
    \State Compute the $\left(1-\alpha\right)$-sample quantile of $t^*_1, t^*_2, \dots, t^*_B$, call this $\hat{t}$.
    \State The joint confidence region of $\theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}$ is given by
        \Statex \begin{minipage}{\linewidth}
        \centering
        $\mathfrak{R}_2 = \left[ \hat\theta_{(1)} \pm \hat t \times \hat\sigma_{(1)}  \right] \times \left[ \hat\theta_{(2)} \pm \hat t \times \hat\sigma_{(2)}  \right] \times \dots \times \left[ \hat\theta_{(K)} \pm \hat t \times \hat\sigma_{(K)}  \right]$
        \end{minipage}
        where $\hat \sigma_{(k)}$ is computed as
        \Statex \begin{minipage}{\linewidth}
    \centering
$\hat\sigma_{(k)} = \sqrt{\text{kth ordered value among} \ \left\{ \hat{\theta}^{2}_{1} + \sigma_1^2, \hat{\theta}^{2}_{2} + \sigma_2^2, \dots, \hat{\theta}^{2}_{K} + \sigma_K^2 \right\} - \hat {\theta}^{2}_{(k)}}$
\end{minipage}
    \end{algorithmic} 
\end{algorithm}

The expression for the asymptotic variance of $\hat{\theta}_{(k)}$ has actually been derived in a setting where the $\hat{\theta}_1,\hat{\theta}_2,\ldots,\hat{\theta}_K$ are independent. It is not clear if the expression in (\ref{eq:rev5}) holds whenever $\hat{\theta}_1,\hat{\theta}_2,\ldots,\hat{\theta}_K$ are correlated. Since this thesis allows for the $\hat{\theta}_k$s to be correlated, it is possible that the expression in (\ref{eq:rev6}) for the estimate of the variance of $\hat{\theta}_{(k)}$ lacks optimality.  As an alternative to using the asymptotic variance, we shall also consider using the bootstrap to estimate the variance of $\hat{\theta}_{(k)}$. To this end, a second-level bootstrap can be employed to estimate the variance. Algorithm  \ref{alg:rank_secondlevelbs} illustrates the procedure to compute the joint confidence region for the ordered parameters with the use of the bootstrap to estimate the variance of the ordered estimates. As may be expected, this approach is computationally intensive.


\begin{algorithm}[H]
    \caption{Computing the joint confidence region for the ordered parameters using the bootstrap estimate of the variance}
    \label{alg:rank_secondlevelbs}
    \begin{algorithmic}[1]
        \For {$b = 1, 2, \dots, B$}
            \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent} 
                Generate $\hat{\boldsymbol{\theta}}^*_b = \left( \hat{\theta}^*_{b1}, \hat{\theta}^*_{b2}, \dots, \hat{\theta}^*_{bK} \right)' \sim N_K \left( \hat{\boldsymbol{\theta}}, \boldsymbol {\Sigma} \right)$ and let $\hat{\theta}_{b(1)}^*, \hat{\theta}_{b(2)}^*, \dots, \hat{\theta}_{b(K)}^*$ be the corresponding ordered values of $\hat{\theta}_{b1}^*, \hat{\theta}_{b2}^*, \dots, \hat{\theta}_{bK}^*$
            \end{minipage}
            \For {$c = 1, 2, \dots, C$}
                \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent} Generate $\hat{\boldsymbol{\theta}}^{**}_{bc} = \left( \hat{\theta}^{**}_{bc1}, \hat{\theta}^{**}_{bc2}, \dots, \hat{\theta}^{**}_{bcK} \right) \sim N_K \left( \hat{\boldsymbol{\theta}}_b^*, \boldsymbol {\Sigma} \right)$ and let $\hat{\theta}^{**}_{bc(1)}, \hat{\theta}^{**}_{bc(2)}, \dots, \hat{\theta}^{**}_{bc(K)}$ be the corresponding ordered values of $\hat{\theta}^{**}_{bc1}, \hat{\theta}^{**}_{bc2}, \dots, \hat{\theta}^{**}_{bcK}$
                \end{minipage}
                \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent} Compute
                $\displaystyle \hat{\sigma}^*_{b(k)} = \sqrt{ \frac{\sum^C_{c=1} \left( \hat \theta^{**}_{bc(k)} - \bar {\hat\theta}^{**}_{b \cdot (k)} \right)^2}{C-1}}, \quad \bar {\hat\theta}^{**}_{b\cdot(k)} = \frac{1}{C} \sum^C_{c=1} {\hat\theta}^{**}_{bc(k)}$
                \end{minipage}
                \EndFor
        \State Compute
                $t_b^* = \underset{1 \leq k <K}{\max} \Bigg \lvert \frac{\hat{\theta}^*_{b(k)}-\hat{\theta}_{(k)}}{\hat \sigma ^* _{b(k)}} \Bigg \rvert$
        \EndFor
        \State Compute the $\left( 1-\alpha \right)$-sample quantile of $t^*_1, t^*_2, \dots, t^*_B$, call this $\hat t$.
        \State The joint confidence region of $\theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}$ is
            \Statex \begin{minipage}{\linewidth}
            \centering
            $\mathfrak{R}_2 = \left[ \hat\theta_{(1)} \pm \hat t \times \hat\sigma_{(1)}  \right] \times \left[ \hat\theta_{(2)} \pm \hat t \times \hat\sigma_{(2)}  \right] \times \dots \times \left[ \hat\theta_{(K)} \pm \hat t \times \hat\sigma_{(K)}  \right]$
        \end{minipage}
        where $\hat \sigma_{(k)}$ is computed as
        \Statex \begin{minipage}{\linewidth}
    \centering
$\displaystyle \hat \sigma_{(k)} = \sqrt{ \frac{\sum^B_{b=1} \left( \hat \theta^*_{b(k)} - \bar {\hat\theta}^*_{\cdot (k)} \right)^2}{B-1}}, \quad \bar {\hat\theta}^*_{\cdot(k)} = \frac{1}{B} \sum^B_{b=1} {\hat\theta}^*_{b(k)}$
\end{minipage}
    \end{algorithmic} 
\end{algorithm}

## Correlation structures {#sec:corrstructures}

The proposed methodologies assume that $V(\hat{\boldsymbol{\theta}})=\boldsymbol{\Sigma}$ is known. Note that we can express $\boldsymbol{\Sigma}$ as in (\ref{eq:sigma_matrix}), where $\mathbf{R}$ is the population correlation matrix.

\begin{equation}
  \boldsymbol{\Sigma} = \boldsymbol{\Delta}^{1/2} \mathbf{R} \boldsymbol{\Delta}^{1/2}; \quad \boldsymbol{\Delta} = \text{diag} \left\{ \sigma^2_1, \sigma^2_2, \dots, \sigma^2_K \right\}.
  \label{eq:sigma_matrix}
\end{equation}
The diagonal elements of $\boldsymbol{\Sigma}$, which are $\sigma^2_k=V(\hat{\theta}_k)$ for $k =1,2, \ldots,K$, are treated as known quantities in practice. With large sample sizes, the variance estimates are stable enough that they are treated as the actual values. However, there is limited information to use as basis for the correlations among the estimates. In this thesis, we shall be assuming certain correlation structures among the $\hat{\theta}$s.  

One structure that may be used is an equicorrelation matrix shown in (\ref{eq:equicorrelation}). This assumes that the $K$ variables are equally correlated, i.e., that $\rho_{jk}=\rho$ where $\rho \in [-1,1]$ for $j \neq k \in \{1, \dots, K\}$.

\begin{equation}
  \mathbf{R}_{\text{eq}} = \left( 1-\rho \right) \mathbf{I}_K + \rho \boldsymbol{1}_K \boldsymbol{1}'_K = 
\begin{bmatrix}
1 & \rho & \cdots & \rho \\
\rho & 1 & \cdots & \rho \\
\vdots & \vdots & \ddots & \vdots \\
\rho & \rho & \cdots & 1
\end{bmatrix}_{K \times K}
  \label{eq:equicorrelation}
\end{equation}

In a block correlation matrix $\mathbf{R}_{block}$ with $G$ blocks, as represented by @canonical, the correlation between any two variables is determined by the block to which the two variables belong. Each diagonal block represents an equicorrelation structure within group $g$, denoted by

\begin{equation}
  \mathbf{R}_{\text{eq,g}} = \left( 1-\rho_{g} \right) \mathbf{I}_{n_g} + \rho_{g} \boldsymbol{1}_{n_g} \boldsymbol{1}'_{n_g} \notag
\end{equation}
where $\rho_{g}$ is the within-block correlation and $n_g$ is the number of variables in block $g$ such that $\sum_{g=1}^G n_g = K$. The off-diagonal blocks capture between-block correlations, represented by
\begin{align}
\mathbf{C}_{g'g} &= \mathbf{C}_{gg'} = \rho_{gg'}\boldsymbol{1}_{n_g} \boldsymbol{1}'_{n_g} \notag\\
&\text{where}\; g\neq g' \in \{1, \dots, G\} \notag
\end{align}
Thus, the full block correlation matrix can be expressed as in (\ref{eq:blockcorrelation}).
\begin{equation}
  \mathbf{R}_{\text{block}} = 
\begin{bmatrix}
\mathbf{R}_{eq,1} & \mathbf{C}_{12} & \cdots & \mathbf{C}_{1G} \\
\mathbf{C}_{21} & \mathbf{R}_{eq,2} & \cdots & \mathbf{C}_{2G} \\
\vdots & \vdots & \ddots & \vdots \\
\mathbf{C}_{G1} & \mathbf{C}_{G2} & \cdots & \mathbf{R}_{eq,G}
\end{bmatrix}_{K \times K}
  \label{eq:blockcorrelation}
\end{equation}
In the context of pre-election surveys, each block may represent correlations induced by party or ticket membership, reflecting stronger associations within parties and weaker associations between them.

Correlation structures that account for spatial proximity can be borrowed from geostatistics. This is particularly relevant in light of Klein’s observation that states located within certain regions exhibit similar travel time characteristics. In such cases, spatial dependence can be modeled using a stationary (i.e., no directional dependence) Matérn correlation function, which for two locations $\mathbf{s}_i$ and $\mathbf{s}_j$ is expressed as in (\ref{eq:matern}).

\begin{equation}
\rho_{\text{matern}} = \frac{2^{1-\nu}}{\Gamma(\nu)} (\kappa \;\Vert \;\mathbf{s}_i - \mathbf{s}_j \; \Vert)^\nu K_\nu  (\kappa \;\Vert \;\mathbf{s}_i - \mathbf{s}_j \; \Vert)
  \label{eq:matern}
\end{equation}
where $\Vert \cdot \Vert$ denotes the Euclidean distance and $K_\nu$ is the second kind of the modified Bessel function. It has a scale parameter $\kappa > 0$ and a smoothness parameter $\nu > 0$. $\rho_{\text{matern}}$ reduces to the exponential correlation when $\nu = 0.5$ and to Gaussian correlation function when $\nu = \infty$. In this paper, the R package "BayesNGSP" (@BayesNGSP), is used to construct the $\mathbf{R}_{\text{matern}}$.

## Evaluation {#sec:evaluation}

Algorithm \ref{alg:evaluation} estimates the coverage probabilities associated with the proposed methodologies. The coverage probabilities correspond to the proportion of replications in which the true parameter values are contained within the confidence intervals for all $K$ simultaneously. Moreover, the tightness of the joint confidence region that results from Algorithm \ref{alg:nonrank_ci} is assessed using three summary measures: the arithmetic mean (\(T_1\)), geometric mean (\(T_2\)), and the metric \(T_3\) introduced by Wright (2025), as presented in Equations \ref{eq:t1}--\ref{eq:t3}.

\begin{equation}
  T_1 = \frac{1}{K} \sum^K_{k=1} \Big | \Lambda_{Ok} \Big|
  \label{eq:t1}
\end{equation} \begin{equation}
  T_2 = \prod^K_{k=1} \Big | \Lambda_{Ok} \Big|
  \label{eq:t2}
\end{equation}

\begin{equation}
  T_3 = 1 - \frac{OP}{K^2}
  \label{eq:t3}
\end{equation} 
In equation \ref{eq:t3}, $OP = K + \sum^K_{k=1} \big | \Lambda_{Ok} \big|$ denotes the total number of occupied positions in a joint confidence region out of the total number of positions $K^2$; or the sum of the differences between the upper and lower bound of the simultaneous rank intervals added by 1, for each $k$. Higher values of $T_1$ and $T_2$ indicate wider confidence intervals and are therefore less desirable, whereas higher values of $T_3$ are preferable. $T_3$ can range from 0, indicating no tightness, to $\frac{K-1}{K}$, implying the confidence region only contains the estimated ranking which is likely the true ranking.

\begin{algorithm}[H]
\fontsize{15pt}{18pt}\selectfont
    \caption{Computing the coverage probability and tightness measures} 
    \label{alg:evaluation}
    For given values of $\boldsymbol{\Sigma}$ and $\theta_1, \theta_2, \dots, \theta_K$ (with corresponding $\theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}$ for rank-based methods)
    \begin{algorithmic}[1] % Start algorithmic block
            \For {$\text{replications} = 1, 2, \dots, 5000$}
            \State Generate $\hat{\boldsymbol{\theta}} \sim N_K(\boldsymbol{\theta}, \boldsymbol{\Sigma})$
            \State Compute the confidence region for the unordered (ordered) parameters using Algorithm \ref{alg:nonrank_ci} ($\mathfrak{R}_1$) (Algorithms \ref{alg:rank_asymp} and \ref{alg:rank_secondlevelbs} ($\mathfrak{R}_2$)), Bonferroni ($\mathfrak{R}_{\text{bonf}}$), and independence assumption ($\mathfrak{R}_{\text{ind}}$).
            \State Check if $\left( \theta_1, \theta_2, \dots, \theta_K\right) \in \mathfrak{R}_1, \mathfrak{R}_{\text{bonf}}, \mathfrak{R}_{\text{ind}}$ $\left(\left( \theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}\right) \in \mathfrak{R}_2\right)$ for the unordered parameters (ordered parameters) and compute $T_1, T_2$, and $T_3$.
        \EndFor
    \State Compute the coverage in line 4 is satisfied and the average of $T_1, T_2$, and $T_3$. Results of Algorithm \ref{alg:nonrank_ci} ($\mathfrak{R}_1$) is compared to ($\mathfrak{R}_{\text{bonf}}$ and $\mathfrak{R}_{\text{ind}}$).
    \end{algorithmic} % End algorithmic block
\end{algorithm}

## Simulation settings {#sec:simulation-settings}

For the simulation settings to be used in evaluating the performance of the proposed methodologies, we shall be varying the settings for the population mean $\boldsymbol{\theta}$, population variances $\sigma^2_1, \sigma^2_2,\ldots,\sigma^2_K$, population correlation matrix $\mathbf{R}$, and number of populations being ranked $K$. In carrying out the simulations, a nominal level of $1-\alpha=0.95$ will be used. The table below summarizes the simulation settings.


\begin{table}[H]
\centering
{\fontsize{13pt}{17pt}\selectfont 
\begin{tabular}{p{11cm} p{4cm}}
\hline
$\boldsymbol{\theta}$ & $\mathbf{R}$ \\
\hline
\hline

\multicolumn{2}{c}{\textbf{K = 10}} \\
\hline
\multirow{3}{11cm}{(22.5, 24.9, 27.5, 24.3, 24.8, 23.2, 23, 21.6, 25.1, 19)$'$} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
\hline
\multirow{3}{11cm}{(21.5, 25.7, 30.5, 24.7, 25.5, 22.6, 22.3, 19.9, 26.1, 15.2)$'$} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\

\hline
\multirow{3}{11cm}{(19.9, 27, 34.9, 25.3, 26.7, 21.9, 21.3, 17.3, 27.7, 9.4)$'$} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
\hline
\multicolumn{2}{c}{\textbf{K = 20}} \\
\hline
\multirow{3}{11cm}{(22.5, 24.9, 27.5, 24.3, 24.8, 23.2, 23, 21.6, 25.1, 19, 21.3, 24.1, 26.5, 26.9, 23.2, 25.8, 21.8, 21.6, 25.6, 21.2)$'$} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
& \\
\hline
\multirow{3}{11cm}{(21.5, 25.7, 30.5, 24.7, 25.5, 22.6, 22.3, 19.9, 26.1, 15.2, 19.3, 24.3, 28.7, 29.3, 22.7, 27.5, 20.1, 19.9, 27.1, 19.1)$'$} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
& \\
\hline
\multirow{3}{11cm}{(19.9, 27, 34.9, 25.3, 26.7, 21.9, 21.3, 17.3, 27.7, 9.4, 16.2, 24.6, 31.9, 33, 21.9, 29.9, 17.7, 17.3, 29.3, 16)$'$} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
& \\
\hline
\multicolumn{2}{c}{\textbf{K = 30}} \\
\hline
\multirow{4}{*}{%
  \parbox{11cm}{%
  \vspace{0.2cm}
    (22.5, 24.9, 27.5, 24.3, 24.8, 23.2, 23, 21.6, 25.1, 19, 
    21.3, 24.1, 26.5, 26.9, 23.2, 25.8, 21.8, 21.6, 25.6, 21.2, 
    25.7, 22.2, 22.7, 22.6, 21.9, 24.2, 23.6, 22, 24.5, 25)$'$
    \vspace{0.2cm}
  }%
} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
& \\
& \\
\hline
\multirow{4}{*}{%
  \parbox{11cm}{%
  \vspace{0.2cm}
  (21.5, 25.7, 30.5, 24.7, 25.5, 22.6, 22.3, 19.9, 26.1, 15.2, 19.3, 24.3, 28.7, 29.3, 22.7, 27.5, 20.1, 19.9, 27.1, 19.1, 27.2, 20.9, 21.8, 21.7, 20.4, 24.5, 23.5, 20.5, 25.1, 26)$'$
    \vspace{0.2cm}
  }%
} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
& \\
& \\
\hline
\multirow{4}{*}{%
  \parbox{11cm}{%
  \vspace{0.2cm}
  (19.9, 27, 34.9, 25.3, 26.7, 21.9, 21.3, 17.3, 27.7, 9.4, 16.2, 24.6, 31.9, 33, 21.9, 29.9, 17.7, 17.3, 29.3, 16, 29.4, 19, 20.4, 20.3, 18.2, 25, 23.3, 18.3, 26, 27.4)$'$
    \vspace{0.2cm}
  }%
} 
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
& \\
& \\
\hline
\end{tabular}
}
\end{table}





\begin{table}[H]
\centering
{\fontsize{13pt}{17pt}\selectfont 
\begin{tabular}{p{11cm} p{4cm}}
\hline
$\boldsymbol{\theta}$ & $\mathbf{R}$ \\
\hline
\hline
\multicolumn{2}{c}{\textbf{K = 40}} \\
\hline
\multirow{6}{11cm}{(22.5, 24.9, 27.5, 24.3, 24.8, 23.2, 23, 21.6, 25.1, 19, 21.3, 24.1, 26.5, 26.9, 23.2, 25.8, 21.8, 21.6, 25.6, 21.2, 25.7, 22.2, 22.7, 22.6, 21.9, 24.2, 23.6, 22, 24.5, 25, 26.5, 25.1, 25.2, 27.1, 25.3, 22.8, 20.6, 21.1, 26, 26)$'$}
&  \\
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
&  \\
&  \\
&  \\
\hline
\multirow{6}{11cm}{(21.5, 25.7, 30.5, 24.7, 25.5, 22.6, 22.3, 19.9, 26.1, 15.2, 19.3, 24.3, 28.7, 29.3, 22.7, 27.5, 20.1, 19.9, 27.1, 19.1, 27.2, 20.9, 21.8, 21.7, 20.4, 24.5, 23.5, 20.5, 25.1, 26, 28.6, 26.1, 26.4, 29.7, 26.5, 22.1, 18, 18.9, 27.8, 27.8)$'$}
&  \\
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
&  \\
&  \\
&  \\
\hline
\multirow{6}{11cm}{(19.9, 27, 34.9, 25.3, 26.7, 21.9, 21.3, 17.3, 27.7, 9.4, 16.2, 24.6, 31.9, 33, 21.9, 29.9, 17.7, 17.3, 29.3, 16, 29.4, 19, 20.4, 20.3, 18.2, 25, 23.3, 18.3, 26, 27.4, 31.9, 27.7, 28.1, 33.6, 28.2, 20.9, 14.1, 15.6, 30.5, 30.5)$'$}
&  \\
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
&  \\
&  \\
&  \\
\hline
\multicolumn{2}{c}{\textbf{K = 50}} \\
\hline
\multirow{6}{11cm}{(22.5, 24.9, 27.5, 24.3, 24.8, 23.2, 23, 21.6, 25.1, 19, 21.3, 24.1, 26.5, 26.9, 23.2, 25.8, 21.8, 21.6, 25.6, 21.2, 25.7, 22.2, 22.7, 22.6, 21.9, 24.2, 23.6, 22, 24.5, 25, 26.5, 25.1, 25.2, 27.1, 25.3, 22.8, 20.6, 21.1, 26, 26, 22.1, 21.4, 23.2, 22.3, 22.4, 23.1, 21.4, 24.8, 27, 23.4)$'$}
&  \\
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
&  \\
&  \\
&  \\
&  \\
\hline
\multirow{6}{11cm}{(21.5, 25.7, 30.5, 24.7, 25.5, 22.6, 22.3, 19.9, 26.1, 15.2, 19.3, 24.3, 28.7, 29.3, 22.7, 27.5, 20.1, 19.9, 27.1, 19.1, 27.2, 20.9, 21.8, 21.7, 20.4, 24.5, 23.5, 20.5, 25.1, 26, 28.6, 26.1, 26.4, 29.7, 26.5, 22.1, 18, 18.9, 27.8, 27.8, 20.8, 19.5, 22.8, 21.2, 21.3, 22.5, 19.5, 25.5, 29.6, 23)$'$}
&  \\
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
&  \\
&  \\
&  \\
&  \\
\hline
\multirow{6}{11cm}{(19.9, 27, 34.9, 25.3, 26.7, 21.9, 21.3, 17.3, 27.7, 9.4, 16.2, 24.6, 31.9, 33, 21.9, 29.9, 17.7, 17.3, 29.3, 16, 29.4, 19, 20.4, 20.3, 18.2, 25, 23.3, 18.3, 26, 27.4, 31.9, 27.7, 28.1, 33.6, 28.2, 20.9, 14.1, 15.6, 30.5, 30.5, 18.8, 16.6, 22.1, 19.4, 19.6, 21.6, 16.7, 26.7, 33.5, 22.5)$'$}
&  \\
& $\mathbf{R}_{\text{eq}}, \rho = 0.1, 0.5, 0.9$ \\
& $\mathbf{R}_{\text{block}}$ - \text{2, 3 blocks} \\
&  \\
&  \\
&  \\
&  \\
\hline
\end{tabular}
}
\end{table}



\begin{table}[H]
\centering
\fontsize{13pt}{20pt}\selectfont
\begin{tabular}{p{1cm} p{14cm}}
\hline
\textbf{K} & \textbf{$\boldsymbol \sigma$} \\
\hline
\hline
10 & (0.14, 0.33, 0.15, 0.23, 0.07, 0.19, 0.19, 0.37, 0.32, 0.11)$'$ \\
\hline
20 & (0.14, 0.33, 0.15, 0.23, 0.07, 0.19, 0.19, 0.37, 0.32, 0.11, 0.17, 0.27, 0.24, 0.11, 0.11, 0.13, 0.16, 0.15, 0.15, 0.25)$'$ \\
\hline
30 & (0.14, 0.33, 0.15, 0.23, 0.07, 0.19, 0.19, 0.37, 0.32, 0.11, 0.17, 0.27, 0.24, 0.11, 0.11, 0.13, 0.16, 0.15, 0.15, 0.25, 0.15, 0.13, 0.1, 0.1, 0.24, 0.13, 0.32, 0.19, 0.27, 0.3)$'$ \\
\hline
40 & (0.14, 0.33, 0.15, 0.23, 0.07, 0.19, 0.19, 0.37, 0.32, 0.11, 0.17, 0.27, 0.24, 0.11, 0.11, 0.13, 0.16, 0.15, 0.15, 0.25, 0.15, 0.13, 0.1, 0.1, 0.24, 0.13, 0.32, 0.19, 0.27, 0.3, 0.12, 0.27, 0.09, 0.12, 0.36, 0.09, 0.15, 0.16, 0.09, 0.29)$'$ \\
\hline
50 & (0.14, 0.33, 0.15, 0.23, 0.07, 0.19, 0.19, 0.37, 0.32, 0.11, 0.17, 0.27, 0.24, 0.11, 0.11, 0.13, 0.16, 0.15, 0.15, 0.25, 0.15, 0.13, 0.1, 0.1, 0.24, 0.13, 0.32, 0.19, 0.27, 0.3, 0.12, 0.27, 0.09, 0.12, 0.36, 0.09, 0.15, 0.16, 0.09, 0.29, 0.16, 0.28, 0.14, 0.07, 0.2, 0.31, 0.13, 0.14, 0.31, 0.11)$'$ \\
\hline
\end{tabular}
\end{table}