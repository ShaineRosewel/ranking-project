---
author: "Matala, Shaine Rosewel"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
fontsize: 11pt
bibliography: /home/realiseshewon/PDev/kde-ranking/writeup/references.bib
csl: /home/realiseshewon/PDev/kde-ranking/writeup/harvard-educational-review.csl
output:
  beamer_presentation:
    keep_tex: true
    theme: "Madrid"
    colortheme: "beaver"
    fonttheme: "structurebold"
    incremental: false
    pandoc_args: ["--lua-filter=filter.lua"]
header-includes:
  - |
    \title[Joint Confidence Regions for Rankings]{Joint Confidence Regions for Rankings based on Correlated Estimates}
    \author[Matala]{Matala, Shaine Rosewel}
    \institute[UP Stat]{University of the Philippines}
    \usepackage{algorithm}
    \usepackage{algpseudocode}
    \usepackage{pgfpages}
    \setbeameroption{show notes on second screen=right}
    \usepackage{comment}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# pandoc_args: ["--lua-filter=filter.lua","--variable=handout"]
# classoption: "handout"
# \setbeameroption{hide notes}
```

\maketitle

# Background of the Study

>- In the problem of estimating ranks of several unknown real-valued parameters $\theta_1,\theta_2,\ldots, \theta_K$, it is desired to rank these $K$ parameters from smallest to largest, $\theta_{(1)}<\theta_{(2)}<\ldots<\theta_{(K)}$.
>- Given estimates in a table without an explicit ranking, readers tend to compare units by looking for smallest or largest estimates and for relative standings between the units. 
>- Because rankings based on $\hat\theta_1,\hat\theta_2,\ldots, \hat\theta_K$ can vary due to sampling variability, statements of uncertainty should accompany released rankings.
>- The margin of error gives uncertainty in $\hat\theta_k$ for each $k$ separately.
>- A direct assessment of the uncertainty in the estimated overall ranking would simultaneously involve all units.

```{=latex}
\note{
\begin{itemize}
  \item Example 30 day mortality rate in hospitals, mean travel time to work by Klein
  \item Such tables motivate "implicit" rankings.
  \item Because rankings based on the observed values of $\hat\theta_1,\hat\theta_2,\ldots, \hat\theta_K$ can vary because of sampling variability, widely understood statements of uncertainty should accompany each released ranking.
  \item While the margin of error gives uncertainty in the estimate $\hat\theta_k$ for each unit $k$ separately, A direct assessment of the uncertainty in the estimated overall ranking would jointly involve all units and their relative standing to each other.
\end{itemize}
}
```

# Background of the Study

>- Let $r_1,r_2,\ldots,r_K$ be the true unknown ranks of $\theta_1,\theta_2,\ldots, \theta_K$. A mathematical definition of $r_k$ is as follows:
\begin{equation}
  r_k = \sum^K_{j=1} I(\theta_j \leq \theta_k) = 1 + \sum_{j:j \neq k} I(\theta_j \leq \theta_k), \qquad \text{for} \; k = 1, 2, \dots, K.
  \label{eq:rank1}
\end{equation}
>- Example

\begin{center}
\uncover<2->{
\begin{tabular}{ |c|c|c| }
\hline
$k$ & $\hat\theta_k$ & $\hat r_k$ \\
\hline \hline
1 & \uncover<3->{12} & \uncover<4->{1} \\
2 & \uncover<3->{17} & \uncover<5->{2} \\  
3 & \uncover<3->{19} & \uncover<7->{5} \\  
4 & \uncover<3->{18} & \uncover<6->{3} \\  
5 & \uncover<3->{19} & \uncover<7->{5} \\  
\hline
\end{tabular}
}

\uncover<8->{$\longrightarrow \left( \hat \theta_{(1)}, \hat \theta_{(2)}, \hat \theta_{(3)}, \hat \theta_{(4)}, \hat \theta_{(5)} \right)' = (12, 17, 18, 19, 19)'$}
\end{center}


::: hidden
# Example

\begin{center}
\begin{tabular}{ |c|c|c| }
\hline
$k$ & $\hat\theta_k$ & $\hat r_k$ \\
\hline \hline
1 & \uncover<2->{12} & \uncover<3->{1} \\
2 & \uncover<2->{17} & \uncover<4->{2} \\  
3 & \uncover<2->{19} & \uncover<6->{5} \\  
4 & \uncover<2->{18} & \uncover<5->{3} \\  
5 & \uncover<2->{19} & \uncover<6->{5} \\  
\hline
\end{tabular}

\uncover<6->{$\longrightarrow \left( \hat \theta_{(1)}, \hat \theta_{(2)}, \hat \theta_{(3)}, \hat \theta_{(4)}, \hat \theta_{(5)} \right)' = (12, 17, 18, 19, 19)'$}
\end{center}
:::

# Klein's

Suppose that for each \(k \in \left\{1, 2, \dots, K\right\}\) there exists values \(L_k\) and \(U_k\) ST

\begin{equation}
  \theta_k \in \left( L_k, U_k \right), k=1,2,\ldots,K.
  \label{eq:theta_int}
\end{equation}

\uncover<2->{
If the condition in (\ref{eq:theta_int}) holds, the main result from Klein et al. (2020) gives a range for the value of \(r_k\) for each \(k \in \left\{1, 2, \dots, K\right\}\) as follows:

\begin{equation}
  r_k \in 
  \left\{ 
  \lvert \Lambda_{Lk} \rvert + 1,  
  \lvert \Lambda_{Lk} \rvert + 2,
  \lvert \Lambda_{Lk} \rvert + 3,
  \dots,
  \lvert \Lambda_{Lk} \rvert + \lvert \Lambda_{Ok} \rvert + 1
  \right\}
  \label{eq:klein_jcs}
\end{equation}

where

\begin{align}
  \Lambda_{Lk} &= \left\{ j\in I_k \mid U_j \le L_k \right\} \\
  \Lambda_{Ok} &= \left\{ j\in I_k \mid U_j > L_k \text{ and } U_k > L_j \right\} \\
  I_k &= \left\{1,2,\dots,K\right\}\setminus\left\{k\right\}
\end{align}
}


# Example
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| }
\hline
$k$ & $\hat\theta_k$ & $\hat r_k$ & $(L_k, U_k)$ & $\vert \Lambda_{L_k} \vert$ & $\vert \Lambda_{O_k} \vert$ & range \\
\hline \hline
1 & {12} & {1} & \uncover<2->{(11, 14)} & \uncover<4->{0} & \uncover<7->{0} & \uncover<10->{1} \\
2 & {17} & {2} & \uncover<3->{(14, 21)} & \uncover<5->{1} & \uncover<8->{3} & \uncover<11->{2,3,4,5} \\  
3 & {19} & {5} & \uncover<3->{(18, 20)} & \uncover<6->{2} & \uncover<9->{2} & \uncover<12->{3,4,5} \\  
4 & {18} & {3} & \uncover<3->{(17, 18)} & \uncover<6->{1} & \uncover<9->{1} & \uncover<12->{2,3} \\  
5 & {19} & {5} & \uncover<3->{(18, 21)} & \uncover<6->{2} & \uncover<9->{2} & \uncover<12->{3,4,5} \\  
\hline
\end{tabular}
\end{center}

# Klein's

Suppose that for random quantities \(L_k\) and \(U_k\) the event defined in (\ref{eq:theta_int}) satisfies the following probability condition:

\begin{equation}
  P\left[ \bigcap^K_{k=1} \left\{ \theta_k \in \left(L_k, U_k\right) \right\} \right] \geq 1-\alpha,
  \label{eq:joint_cov1}
\end{equation}

\uncover<2->{
then, by the result of Klein et al. (2020), it also follows that

\begin{equation}
  P\left[
  \bigcap^K_{k=1}
  \left\{
  r_k \in 
  \left\{ 
  \lvert \Lambda_{Lk} \rvert + 1,  
  \lvert \Lambda_{Lk} \rvert + 2,
  \dots,
  \lvert \Lambda_{Lk} \rvert + \lvert \Lambda_{Ok} \rvert + 1
  \right\}
  \right\}
  \right] \geq 1-\alpha.
  \label{eq:joint_cov2}
\end{equation}
}

# Other related studies

>- Mohamad et al. (2019) apply Tukey's Honest Significant Difference (HSD) to test $H_0: \theta_j - \theta_{k} = 0$ for all $j \neq k \in {1, ..., K}$ at level $\alpha$.
>- Mogstad et al. (2024) construct the rectangular confidence region from the pairwise differences of the estimators $\hat{\theta}_1, \dots, \hat{\theta}_K$ and an estimator of the variance of $\hat{\theta}_{j}-\hat{\theta}_{k}$.

```{=latex}
\note{
\begin{itemize}
  \item their approach tends to be overly conservative, showing coverage levels between 0.996 and 1.0 at a 0.90 nominal level in simulations, when the $\theta$s differ. They also demonstrated that as the true differences increase from 0 to 0.5, the coverage quickly increases from the nominal level to 1. As a remedy, they proposed a rescaling technique that brings the coverage closer to the nominal level, though it remains conservative (e.g., from 1.0 to 0.978, from 0.998 to 0.961---at 0.90 confidence level
\end{itemize}
}
```

# Other related studies

>- Goldstein \& Spiegelhalter (1996) use multilevel models, in the context of ranking education and health institutions (e.g., schools, hospitals, medical practitioners, etc.), to address the hierarchical nature of data structures associated with institutional performance.
>- Hall \& Miller (2009) suggest using an "independent component" version of the bootstrap on the sample, where m-out-of-n bootstrap (m < n) is applied as though the ranked variables were statistically independent. 
>- Zhang et al. (2013) analyze U.S. age-adjusted cancer incidence and mortality rates across states and counties by computing individual and overall simultaneous confidence intervals for age-adjusted health index using the Monte Carlo method.
>- Bazylik et al. (2025), in their recent study, tackle the ranking of political candidates or parties using the estimated share of support each one receives in surveys. They address the dependence attributed to the success probabilities of different categories by using their proposed bootstrap
algorithm.


```{=latex}
\note{
\begin{itemize}
  \item hall and miller: They show this to perform at its best when a reasonable level of correlation is present among the variables.
\end{itemize}
}
```


# Motivation

>- Problem: Assuming independence when constructing joint confidence regions for estimators that are, in fact, correlated may lead to overly conservative and thus wider intervals, implying greater uncertainty.
>- Aim: develop a procedure capable of handling such dependencies while maintaining coverage close to the nominal level and producing relatively narrow joint confidence intervals.

# Motivation

## Political setting --- David \& Legara (2015)
>- Name recall is a powerful predictor of likely victory in elections.
>- In weak-party systems, candidates who belong to the same political alliance or ticket commonly co-occur in ballots and hence perform with similarity.


```{=latex}
\note{
\begin{itemize}
  \item Candidates with a name-recall advantage, such as media celebrities, incumbents, and members of dynastic families, received majority of the votes in the 2010 senatorial elections
  \item top-ranked candidates is composed of people who can take the most advantage of name recall: All belong to at least one of the following types: media celebrity, member of political dynasty, or had prior experience in the Senate (labeled henceforth Celebrities and Dynasties). Of the eight candidates, three are former movie and television actors, three are offspring of former presidents and senators, and six had prior experience in the Senate. They come from different political parties and different tickets
  \item This set of candidates was aggressively campaigned alongside candidate for President Aquino, who was popular
throughout the election season and eventually won by a 12% margin.This is the only ticket-based cluster;
\end{itemize}
}
```

# Motivation

## Measurement across geographies --- Klein et al. (2020)

\begin{table}[h]
\centering
\begin{tabular}{p{1cm} p{4.5cm} p{4.5cm}}
\textbf{Travel Time} & \textbf{Population Density} & \textbf{Common Locations} \\ \hline
\uncover<2->{Shorter mean} &
\uncover<3->{Large unpopulated land areas; fewer high-density population centers} &
\uncover<5->{Mountain region and Central region states} \\[3pt] %3pt is the gap%
\uncover<2->{Longer mean} &
\uncover<4->{Highly urbanized areas with large populations and dense population centers} &
\uncover<6->{East Coast states} \\
\end{tabular}
\end{table}

```{=latex}
\note{
\begin{itemize}
  \item Klein et al. (2020) also noted that states with large unpopulated land areas and relatively few high-density population centers tend to report shorter travel times while longer travel times are typically observed in highly urbanized states with large populations and high population densities.
  \item 2019---Many states with shorter travel times are located in the Mountain and Central regions, whereas majority of those with longer travel times are concentrated along the East Coast.
\end{itemize}
}
```


# Objective

This research aims to do the following:

>- Develop a procedure to construct joint confidence intervals for the ranks and the ranked parameters when the estimates to be ranked may be correlated.
>- Evaluate the performance of the proposed approaches under various
parameter settings.
>- Apply the proposed approaches to a real-life example.

# Definitions and Assumptions

>- Define $\hat{\boldsymbol{\theta}}=(\hat{\theta}_1,\hat{\theta}_2,\ldots,\hat{\theta}_K)'$ and assume that $\hat{\boldsymbol{\theta}}\sim N(\boldsymbol{\theta},\boldsymbol{\Sigma})$ where $\boldsymbol{\theta}=(\theta_1,\theta_2,\ldots,\theta_K)'$ is unknown and $\boldsymbol{\Sigma}$ is a known $K \times K$ positive definite matrix. The diagonal elements of $\boldsymbol{\Sigma}$ are $\sigma^2_1,\ldots,\sigma^2_K$.  
>- Note that in the literature on inferences on the ranks, it is customary to assume that the variances are known.

# Procedure

>1. Derive simultaneous confidence intervals for $\theta_1,\theta_2,\ldots,\theta_K$ of the form 
\begin{equation}
\mathfrak{R}_1 = 
[\hat{\theta}_1 \pm t \times \sigma_1] \times
[\hat{\theta}_2 \pm t \times \sigma_2] \times
\cdots \times
[\hat{\theta}_K \pm t \times \sigma_K].
  \label{eq:rev1}
\end{equation}


>2. Once the confidence intervals in (\ref{eq:rev1}) have been obtained, we can then use the result of Klein et al. (2020) in (\ref{eq:joint_cov2}) to get the lower and upper bounds on the ranks $r_k, k=1,2,\ldots,K$.


```{=latex}
\note{
\begin{itemize}
  \item bullet 2: That is, we also get a joint confidence region for $r_1, r_2, . . . , r_K$.
\end{itemize}
}
```


# Proposed methodology to compute the joint confidence region for the unordered parameters: Algorithm 1 

Let the data be represented by $\hat{\boldsymbol{\theta}} = \left( \hat \theta_1, \hat \theta_2, \dots, \hat \theta_K \right)'$ and suppose that $\boldsymbol{\Sigma}$ is known
    \begin{algorithmic}[1]
        \For {$b = 1, 2, \dots, B$}
                \State Generate $\hat{\boldsymbol{\theta}}^*_b \sim N_K \left( \hat{\boldsymbol{\theta}}, \boldsymbol{\Sigma}\right)$ and write $\hat{\boldsymbol{\theta}}^*_b = \left( \hat\theta^*_{b1}, \hat\theta^*_{b2}, \dots, \hat\theta^*_{bK} \right)' $
                \State Compute 
                \Statex \begin{minipage}{\linewidth}
                \centering
                $t^*_b = \underset{1 \leq k \leq K}{\max} \Bigg| \frac{\hat\theta^*_{bk} - \hat\theta_{k}}{\sigma_k} \Bigg|$
                \end{minipage}
        \EndFor
        \State Compute the $\left(1-\alpha\right)$-sample quantile of $t^*_1, t^*_2, \dots, t^*_B$, call this $\hat{t}$.
        \State The joint confidence region for $\boldsymbol{\theta} = (\theta_1, \theta_2, \dots, \theta_K)'$ is given by 
        \Statex \begin{minipage}{\linewidth}
    \centering
$\mathfrak{R}_1 = \left[ \hat\theta_1 \pm \hat t \times \sigma_1  \right] \times \left[ \hat\theta_2 \pm \hat t \times \sigma_2  \right] \times \dots \times \left[ \hat\theta_K \pm \hat t \times \sigma_K  \right]$.
    \end{minipage}
    \end{algorithmic} 
    
# Algorithm 1: Quantile Calculation
    
We want the joint confidence region in (\ref{eq:rev1}) to satisfy the following probability condition:

\begin{equation}
 P\left( \hat{\theta}_k-t \cdot \sigma_k \leq  \theta_k \leq  \hat{\theta}_k + t \cdot \sigma_k, \,\, \forall\; k=1,2,\ldots,K \right)  =1-\alpha.
\end{equation}

Equivalently, we require

\begin{equation}
 P\left( \max_{k=1,2,\ldots,K} \left| \dfrac{\hat{\theta}_k-\theta_k}{\sigma_k} \right| \le t \right) =1-\alpha. 
\end{equation}

# Proposed methodology to compute a joint confidence region for the ordered parameters {#sec:nonrank}
\begin{minipage}{1.0\textwidth}
\begin{algorithmic}[1]
    \For {$b = 1, 2, \dots, B$}
        \State
            Generate $\hat{\boldsymbol{\theta}}^*_b = \left( \hat{\theta}^*_{b1}, \hat{\theta}^*_{b2}, \dots, \hat{\theta}^*_{bK} \right)' \sim N_K \left( \boldsymbol{\hat \theta}, \boldsymbol {\Sigma} \right)$ and let $\hat{\theta}^*_{b(1)}, \hat{\theta}^*_{b(2)}, \dots, \hat{\theta}^*_{b(K)}$ be the corresponding ordered values 
        \State
        Compute $\hat\sigma^*_{b(k)}$ using:
        \Statex \qquad • asymptotic variance definition
        \Statex \qquad • second-level bootstrap
        \State
            Compute
\Statex
\begin{center}
$t^*_b = \underset{1 \leq k \leq K}{\max} \Bigg| \frac{\hat\theta^*_{b(k)} - \hat\theta^*_{k}}{\hat\sigma^*_{b(k)}} \Bigg|$
\end{center}
    \EndFor
    \State Compute the $\left(1-\alpha\right)$-sample quantile of $t^*_1, \dots, t^*_B$, call this $\hat{t}$.
    \State The joint confidence region of $\theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}$ is given by
\Statex
\begin{center}
    $\mathfrak{R}_2 = \left[ \hat\theta_{(1)} \pm \hat t \times \hat\sigma_{(1)}  \right] \times \left[ \hat\theta_{(2)} \pm \hat t \times \hat\sigma_{(2)}  \right] \times \dots \times \left[ \hat\theta_{(K)} \pm \hat t \times \hat\sigma_{(K)}  \right]$
\end{center}
    \end{algorithmic}
\end{minipage}

# Algorithm 2: Asymptotic Definition of Variance

$\hat\sigma^*_{b(k)} = \sqrt{\left[\text{kth ordered value among} \ \left\{ \hat{\theta}^{*2}_{b1} + \sigma_1^2, \dots, \hat{\theta}^{*2}_{bK} + \sigma_K^2 \right\}\right] - \hat {\theta}^{*2}_{(k)}}$

# Algorithm 3: Variance from Second-Level Bootstrap

\begin{algorithmic}[1]
            \For {$c = 1, 2, \dots, C$}
                \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent} Generate $\hat{\boldsymbol{\theta}}^{**}_{bc} = \left( \hat{\theta}^{**}_{bc1}, \hat{\theta}^{**}_{bc2}, \dots, \hat{\theta}^{**}_{bcK} \right) \sim N_K \left( \hat{\boldsymbol{\theta}}_b^*, \boldsymbol {\Sigma} \right)$ and let $\hat{\theta}^{**}_{bc(1)}, \hat{\theta}^{**}_{bc(2)}, \dots, \hat{\theta}^{**}_{bc(K)}$ be the corresponding ordered values of $\hat{\theta}^{**}_{bc1}, \hat{\theta}^{**}_{bc2}, \dots, \hat{\theta}^{**}_{bcK}$
                \end{minipage}
                \State \begin{minipage}[t]{\dimexpr\linewidth-\algorithmicindent} Compute
                $\displaystyle \hat{\sigma}^*_{b(k)} = \frac{\sum^C_{c=1} \left( \hat \theta^{**}_{bc(k)} - \bar {\hat\theta}^{**}_{b \cdot (k)} \right)^2}{C-1}, \quad \bar {\hat\theta}^{**}_{b\cdot(k)} = \frac{1}{C} \sum^C_{c=1} {\hat\theta}^{**}_{bc(k)}$
                \end{minipage}
                \EndFor
    \end{algorithmic} 

# Evaluation Algorithm

For given values of $\boldsymbol{\Sigma}$ and $\theta_1, \theta_2, \dots, \theta_K$ (with corresponding $\theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}$ for rank-based methods)
    \begin{algorithmic}[1] % Start algorithmic block
            \For {$\text{replications} = 1, 2, \dots, 5000$}
            \State Generate $\hat{\boldsymbol{\theta}} \sim N_K(\boldsymbol{\theta}, \boldsymbol{\Sigma})$
            \State Compute the confidence region $\mathfrak{R}_1$ for the unordered parameters using Algorithm 1 and the confidence region for the ordered parameters $\mathfrak{R}_2$ using Algorithms 2 and 3.
            \State For the unordered parameters, check if $\left( \theta_1, \theta_2, \dots, \theta_K\right) \in \mathfrak{R}_1$ and compute $T_1, T_2$, and $T_3$. For the ordered parameters, check if $\left( \theta_{(1)}, \theta_{(2)}, \dots, \theta_{(K)}\right) \in \mathfrak{R}_2$
        \EndFor
    \State Compute the proportion of times that the condition in line 4 is satisfied and the average of $T_1, T_2$, and $T_3$.
    \end{algorithmic}

# Covariance Matrix $\boldsymbol{\Sigma}$
    
- The covariance matrix $\boldsymbol{\Sigma}$ need not be a diagonal matrix.
- We assume that $V(\hat{\boldsymbol{\theta}})=\boldsymbol{\Sigma}$ is known and express $\boldsymbol{\Sigma}$ as in (\ref{eq:sigma_matrix}), where $\mathbf{R}$ is the population correlation matrix.

\begin{equation}
  \boldsymbol{\Sigma} = \boldsymbol{\Delta}^{1/2} \mathbf{R} \boldsymbol{\Delta}^{1/2}; \quad \boldsymbol{\Delta} = \text{diag} \left\{ \sigma^2_1, \sigma^2_2, \dots, \sigma^2_K \right\}.
  \label{eq:sigma_matrix}
\end{equation}

- The diagonal elements of $\boldsymbol{\Sigma}$, which are $\sigma^2_k=V(\hat{\theta}_k)$ for $k =1,2, \ldots,K$, are treated as known quantities in practice.

# Correlation Structures: Equicorrelation

>- We assume certain correlation structures among the $\hat{\theta}$s.  
>- Equicorrelation is considered for simplicity.  
>- This assumes that the $k$ variables are equally correlated, i.e., that $\rho_{jk}=\rho$ where $\rho \in [-1,1]$ for $j \neq k \in \{1, \dots, K\}$.
\begin{equation}
  \mathbf{R}_{\text{eq}} = \left( 1-\rho \right) \mathbf{I}_K + \rho \boldsymbol{1}_K \boldsymbol{1}'_K = 
\begin{bmatrix}
1 & \rho & \cdots & \rho \\
\rho & 1 & \cdots & \rho \\
\vdots & \vdots & \ddots & \vdots \\
\rho & \rho & \cdots & 1
\end{bmatrix}_{K \times K}
  \label{eq:equicorrelation}
\end{equation}

# Correlation Structures: Block correlation

>- Useful in the context of pre-election surveys
>- In a block correlation matrix $\mathbf{R}_{block}$ with $G$ blocks, each diagonal block represents an equicorrelation structure within group $g$, denoted by
\begin{equation}
  \mathbf{R}_{\text{eq,g}} = \left( 1-\rho_{g} \right) \mathbf{I}_{n_g} + \rho_{g} \boldsymbol{1}_{n_g} \boldsymbol{1}'_{n_g} \notag
\end{equation}
where $\rho_{g}$ is the within-block correlation and $n_g$ is the number of variables in block $g$ such that $\sum_{g=1}^G n_g = K$.  
>- The off-diagonal blocks capture between-block correlations, represented by  $\mathbf{C}_{g'g} = \mathbf{C}_{gg'} = \rho_{gg'}\boldsymbol{1}_{n_g} \boldsymbol{1}'_{n_g}$ where $g\neq g' \in \{1, \dots, G\}$
>- The full block correlation matrix can be expressed as in (\ref{eq:blockcorrelation}).  
\begin{equation}
  \mathbf{R}_{\text{block}} = 
\begin{bmatrix}
\mathbf{R}_{eq,1} & \mathbf{C}_{12} & \cdots & \mathbf{C}_{1G} \\
\mathbf{C}_{21} & \mathbf{R}_{eq,2} & \cdots & \mathbf{C}_{2G} \\
\vdots & \vdots & \ddots & \vdots \\
\mathbf{C}_{G1} & \mathbf{C}_{G2} & \cdots & \mathbf{R}_{eq,G}
\end{bmatrix}_{K \times K}
  \label{eq:blockcorrelation}
\end{equation}


# Correlation Structures: Distance-based correlation

>- Useful in the mean travel time from the study of Klein et al. (2020).
>- Spatial dependence can be modeled using a stationary Matérn correlation function, which for two locations $\mathbf{s}_i$ and $\mathbf{s}_j$ is expressed as
\begin{equation}
\rho_{\text{matern}} = \frac{2^{1-\nu}}{\Gamma(\nu)} (\kappa \;\Vert \;\mathbf{s}_i - \mathbf{s}_j \; \Vert)^\nu K_\nu  (\kappa \;\Vert \;\mathbf{s}_i - \mathbf{s}_j \; \Vert)
  \notag
\end{equation}
where $\Vert \cdot \Vert$ denotes the Euclidean distance and $K_\nu$ is the second kind of the modified Bessel function. It has a scale parameter $\kappa > 0$ and a smoothness parameter $\nu > 0$. $\rho_{\text{matern}}$ reduces to the exponential correlation when $\nu = 0.5$ and to Gaussian correlation function when $\nu = \infty$.

# Simulation settings

The following settings are considered for $K = \{10, 20, 30, 40, 50\}$. Each $K$ has a set of corresponding population variances $\sigma^2_1, \sigma^2_2,\ldots,\sigma^2_K$. A nominal level of $1-\alpha=0.95$ will be used.

\begin{center}
\begin{tabular}{ |c|c| }
\hline
$\boldsymbol{\theta}$ & Correlation matrix \\
\hline \hline
low variability & $\mathbf{R}_{\text{eq}},\, \mathbf{R}_{\text{block}}$ \\
medium variability & $\mathbf{R}_{\text{eq}},\, \mathbf{R}_{\text{block}}$ \\  
high variability & $\mathbf{R}_{\text{eq}},\, \mathbf{R}_{\text{block}}$ \\
\hline
\end{tabular}
\end{center}
